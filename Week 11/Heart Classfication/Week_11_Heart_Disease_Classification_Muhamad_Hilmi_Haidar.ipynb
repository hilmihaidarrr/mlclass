{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# MLP Classification (Heart Disease)"
      ],
      "metadata": {
        "id": "nJinXUqumhxn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Bagian 1: Persiapan Data**"
      ],
      "metadata": {
        "id": "zE9VbZ3jmycK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import time"
      ],
      "metadata": {
        "id": "xYS7dVhSm4nw"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import library** yang digunakan dalam preprocessing data, training model, dan evaluasi menggunakan PyTorch."
      ],
      "metadata": {
        "id": "7wLTEoEGm6xP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/heart.csv')\n",
        "print(\"Dataset Info:\")\n",
        "print(data.info())\n",
        "print(\"\\nDataset Description:\")\n",
        "print(data.describe())\n",
        "print(\"\\nMissing Values:\")\n",
        "print(data.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NzisoDDm8VJ",
        "outputId": "fa377b04-16d9-4610-c88e-f175e02bcec9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1025 entries, 0 to 1024\n",
            "Data columns (total 14 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   age       1025 non-null   int64  \n",
            " 1   sex       1025 non-null   int64  \n",
            " 2   cp        1025 non-null   int64  \n",
            " 3   trestbps  1025 non-null   int64  \n",
            " 4   chol      1025 non-null   int64  \n",
            " 5   fbs       1025 non-null   int64  \n",
            " 6   restecg   1025 non-null   int64  \n",
            " 7   thalach   1025 non-null   int64  \n",
            " 8   exang     1025 non-null   int64  \n",
            " 9   oldpeak   1025 non-null   float64\n",
            " 10  slope     1025 non-null   int64  \n",
            " 11  ca        1025 non-null   int64  \n",
            " 12  thal      1025 non-null   int64  \n",
            " 13  target    1025 non-null   int64  \n",
            "dtypes: float64(1), int64(13)\n",
            "memory usage: 112.2 KB\n",
            "None\n",
            "\n",
            "Dataset Description:\n",
            "               age          sex           cp     trestbps        chol  \\\n",
            "count  1025.000000  1025.000000  1025.000000  1025.000000  1025.00000   \n",
            "mean     54.434146     0.695610     0.942439   131.611707   246.00000   \n",
            "std       9.072290     0.460373     1.029641    17.516718    51.59251   \n",
            "min      29.000000     0.000000     0.000000    94.000000   126.00000   \n",
            "25%      48.000000     0.000000     0.000000   120.000000   211.00000   \n",
            "50%      56.000000     1.000000     1.000000   130.000000   240.00000   \n",
            "75%      61.000000     1.000000     2.000000   140.000000   275.00000   \n",
            "max      77.000000     1.000000     3.000000   200.000000   564.00000   \n",
            "\n",
            "               fbs      restecg      thalach        exang      oldpeak  \\\n",
            "count  1025.000000  1025.000000  1025.000000  1025.000000  1025.000000   \n",
            "mean      0.149268     0.529756   149.114146     0.336585     1.071512   \n",
            "std       0.356527     0.527878    23.005724     0.472772     1.175053   \n",
            "min       0.000000     0.000000    71.000000     0.000000     0.000000   \n",
            "25%       0.000000     0.000000   132.000000     0.000000     0.000000   \n",
            "50%       0.000000     1.000000   152.000000     0.000000     0.800000   \n",
            "75%       0.000000     1.000000   166.000000     1.000000     1.800000   \n",
            "max       1.000000     2.000000   202.000000     1.000000     6.200000   \n",
            "\n",
            "             slope           ca         thal       target  \n",
            "count  1025.000000  1025.000000  1025.000000  1025.000000  \n",
            "mean      1.385366     0.754146     2.323902     0.513171  \n",
            "std       0.617755     1.030798     0.620660     0.500070  \n",
            "min       0.000000     0.000000     0.000000     0.000000  \n",
            "25%       1.000000     0.000000     2.000000     0.000000  \n",
            "50%       1.000000     0.000000     2.000000     1.000000  \n",
            "75%       2.000000     1.000000     3.000000     1.000000  \n",
            "max       2.000000     4.000000     3.000000     1.000000  \n",
            "\n",
            "Missing Values:\n",
            "age         0\n",
            "sex         0\n",
            "cp          0\n",
            "trestbps    0\n",
            "chol        0\n",
            "fbs         0\n",
            "restecg     0\n",
            "thalach     0\n",
            "exang       0\n",
            "oldpeak     0\n",
            "slope       0\n",
            "ca          0\n",
            "thal        0\n",
            "target      0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load dataset** `heart.csv` dan tampilkan informasi terkait struktur data, deskripsi statistik, dan jumlah missing values."
      ],
      "metadata": {
        "id": "DgCJXQUCm-kr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if data.isnull().sum().sum() > 0:\n",
        "    data = data.dropna()  # Drop rows with missing values"
      ],
      "metadata": {
        "id": "xrbYUhrBm-Zy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cek dan **hapus baris yang memiliki missing values** jika ada."
      ],
      "metadata": {
        "id": "mcktT6qynCee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.drop('target', axis=1).values  # Assuming 'target' is the column for classification\n",
        "y = data['target'].values"
      ],
      "metadata": {
        "id": "5t8A9PAUnNTf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pisahkan dataset menjadi **fitur (X)** dan **label target (y)**."
      ],
      "metadata": {
        "id": "wOWB2AAHnHL0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "vV1kjrzznRXx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lakukan **standardisasi fitur** agar memiliki mean = 0 dan standard deviation = 1.\n"
      ],
      "metadata": {
        "id": "bEN2NO8WnTIF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "0HmmRLzznXxV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Split data** menjadi train dan test set dengan proporsi 80:20.\n",
        "\n"
      ],
      "metadata": {
        "id": "Gc-_8FLdnU7v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Bagian 2: Dataset Custom Class**"
      ],
      "metadata": {
        "id": "gnNJrTWXnaO-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create custom Dataset class for PyTorch\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, features, labels):\n",
        "        self.features = torch.tensor(features, dtype=torch.float32)\n",
        "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.features[idx], self.labels[idx]"
      ],
      "metadata": {
        "id": "1ABNsDxendOY"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kelas ini mengimplementasikan PyTorch `Dataset` untuk **mengelola input dan label** dalam bentuk tensor."
      ],
      "metadata": {
        "id": "47J9w6ZznyRd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Bagian 3: Model MLP dengan Dropout, BatchNorm, dan Regularisasi**\n"
      ],
      "metadata": {
        "id": "pIKHOuaRn2xc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the MLP model class with Dropout, BatchNorm, L1/L2 regularization\n",
        "class MLPModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_layers, activation_fn, dropout_rate):\n",
        "        super(MLPModel, self).__init__()\n",
        "        layers = []\n",
        "        for i, hidden_size in enumerate(hidden_layers):\n",
        "            layers.append(nn.Linear(input_size if i == 0 else hidden_layers[i-1], hidden_size))  # Fully connected layer\n",
        "            layers.append(nn.BatchNorm1d(hidden_size))  # Batch normalization layer\n",
        "            if activation_fn == 'relu':\n",
        "                layers.append(nn.ReLU())\n",
        "            elif activation_fn == 'sigmoid':\n",
        "                layers.append(nn.Sigmoid())\n",
        "            elif activation_fn == 'tanh':\n",
        "                layers.append(nn.Tanh())\n",
        "            elif activation_fn == 'linear':\n",
        "                layers.append(nn.Identity())  # Linear activation\n",
        "            elif activation_fn == 'softmax':\n",
        "                layers.append(nn.Softmax(dim=1))\n",
        "            layers.append(nn.Dropout(dropout_rate))  # Dropout for regularization\n",
        "        layers.append(nn.Linear(hidden_layers[-1], 2))  # Output layer with 2 classes\n",
        "        self.model = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)  # Forward pass"
      ],
      "metadata": {
        "id": "Odt9ldxgn3Vj"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MLP Model dengan:\n",
        "  - **Fully connected layers** dan **BatchNorm** di setiap layer.\n",
        "  - **Activation functions**: ReLU, Sigmoid, Tanh, Linear, atau Softmax.\n",
        "  - **Dropout** sebagai regularisasi.\n"
      ],
      "metadata": {
        "id": "X1HoETb3n6ww"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Bagian 4: Fungsi Training dan Evaluasi**"
      ],
      "metadata": {
        "id": "UdGZmOBEn_MG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define function to train and evaluate the model with L1/L2 regularization\n",
        "def train_and_evaluate(hidden_layers, activation_fn, learning_rate, batch_size, epochs, dropout_rate, weight_decay):\n",
        "    # Initialize dataset and dataloaders\n",
        "    train_dataset = CustomDataset(X_train, y_train)\n",
        "    test_dataset = CustomDataset(X_test, y_test)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=8, pin_memory=True)\n",
        "\n",
        "    # Initialize model, loss function, and optimizer\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = MLPModel(input_size=X_train.shape[1], hidden_layers=hidden_layers, activation_fn=activation_fn, dropout_rate=dropout_rate).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()  # Cross-entropy loss for classification\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)  # L2 regularization via weight_decay\n",
        "\n",
        "    # Print parameters being used\n",
        "    print(f\"\\nTraining with Parameters: Hidden Layers={hidden_layers}, Activation={activation_fn}, LR={learning_rate}, Batch Size={batch_size}, Epochs={epochs}, Dropout={dropout_rate}, L2={weight_decay}\")\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(epochs):\n",
        "        start_time = time.time()\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for features, labels in train_loader:\n",
        "            features, labels = features.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(features)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        epoch_time = time.time() - start_time\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(train_loader):.4f}, Time: {epoch_time:.2f}s\")\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for features, labels in test_loader:\n",
        "            features, labels = features.to(device), labels.to(device)\n",
        "            outputs = model(features)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = correct / total * 100\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "fyJK-nAFoA_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Load data** ke dalam PyTorch `DataLoader`.\n",
        "- **DataLoader** digunakan untuk memuat data secara batch.\n",
        "- Menginisialisasi model, loss function (CrossEntropyLoss), dan optimizer (Adam dengan weight decay untuk L2 regularisasi).\n",
        "-  **Training loop**:\n",
        "  - Forward pass → Hitung loss → Backward pass → Update parameter.\n",
        "- **Evaluasi model**: Hitung akurasi pada data uji.\n"
      ],
      "metadata": {
        "id": "CCOvq6WuoEcl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Bagian 5: Eksperimen**"
      ],
      "metadata": {
        "id": "cKvzG71Bowl9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Eksperimen 1: Hidden Layers**\n"
      ],
      "metadata": {
        "id": "G4XMHbf7oyub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 1: Comparing Hidden Layers and Neurons\n",
        "hidden_layers_options = [[4], [8], [16], [32], [64], [4, 4], [8, 8], [16, 16], [32, 16, 8]]  # Fixed to avoid nested lists\n",
        "results_hidden_layers = []\n",
        "for hidden_layers in hidden_layers_options:\n",
        "    accuracy = train_and_evaluate(hidden_layers, activation_fn='relu', learning_rate=0.01, batch_size=32, epochs=50, dropout_rate=0.2, weight_decay=1e-4)\n",
        "    results_hidden_layers.append({'hidden_layers': hidden_layers, 'accuracy': accuracy})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iP0X9HKxovuk",
        "outputId": "6a91e388-9c40-4dbd-813a-afcf876ae71f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training with Parameters: Hidden Layers=[4], Activation=relu, LR=0.01, Batch Size=32, Epochs=50, Dropout=0.2, L2=0.0001\n",
            "Epoch [1/50], Loss: 0.6403, Time: 0.27s\n",
            "Epoch [2/50], Loss: 0.4591, Time: 0.25s\n",
            "Epoch [3/50], Loss: 0.4033, Time: 0.26s\n",
            "Epoch [4/50], Loss: 0.3671, Time: 0.26s\n",
            "Epoch [5/50], Loss: 0.3794, Time: 0.27s\n",
            "Epoch [6/50], Loss: 0.3761, Time: 0.26s\n",
            "Epoch [7/50], Loss: 0.3624, Time: 0.26s\n",
            "Epoch [8/50], Loss: 0.3687, Time: 0.28s\n",
            "Epoch [9/50], Loss: 0.3595, Time: 0.27s\n",
            "Epoch [10/50], Loss: 0.3696, Time: 0.27s\n",
            "Epoch [11/50], Loss: 0.3327, Time: 0.27s\n",
            "Epoch [12/50], Loss: 0.3630, Time: 0.28s\n",
            "Epoch [13/50], Loss: 0.3507, Time: 0.28s\n",
            "Epoch [14/50], Loss: 0.3666, Time: 0.27s\n",
            "Epoch [15/50], Loss: 0.3481, Time: 0.25s\n",
            "Epoch [16/50], Loss: 0.3502, Time: 0.25s\n",
            "Epoch [17/50], Loss: 0.3403, Time: 0.24s\n",
            "Epoch [18/50], Loss: 0.3501, Time: 0.25s\n",
            "Epoch [19/50], Loss: 0.3430, Time: 0.25s\n",
            "Epoch [20/50], Loss: 0.3335, Time: 0.25s\n",
            "Epoch [21/50], Loss: 0.3411, Time: 0.25s\n",
            "Epoch [22/50], Loss: 0.3344, Time: 0.26s\n",
            "Epoch [23/50], Loss: 0.3467, Time: 0.25s\n",
            "Epoch [24/50], Loss: 0.3203, Time: 0.26s\n",
            "Epoch [25/50], Loss: 0.3532, Time: 0.26s\n",
            "Epoch [26/50], Loss: 0.3425, Time: 0.25s\n",
            "Epoch [27/50], Loss: 0.3333, Time: 0.25s\n",
            "Epoch [28/50], Loss: 0.3356, Time: 0.25s\n",
            "Epoch [29/50], Loss: 0.3676, Time: 0.25s\n",
            "Epoch [30/50], Loss: 0.3404, Time: 0.26s\n",
            "Epoch [31/50], Loss: 0.3407, Time: 0.26s\n",
            "Epoch [32/50], Loss: 0.3440, Time: 0.25s\n",
            "Epoch [33/50], Loss: 0.3614, Time: 0.26s\n",
            "Epoch [34/50], Loss: 0.3321, Time: 0.24s\n",
            "Epoch [35/50], Loss: 0.3335, Time: 0.24s\n",
            "Epoch [36/50], Loss: 0.3602, Time: 0.26s\n",
            "Epoch [37/50], Loss: 0.3344, Time: 0.26s\n",
            "Epoch [38/50], Loss: 0.3493, Time: 0.26s\n",
            "Epoch [39/50], Loss: 0.3325, Time: 0.25s\n",
            "Epoch [40/50], Loss: 0.3392, Time: 0.25s\n",
            "Epoch [41/50], Loss: 0.3349, Time: 0.26s\n",
            "Epoch [42/50], Loss: 0.3252, Time: 0.27s\n",
            "Epoch [43/50], Loss: 0.3409, Time: 0.26s\n",
            "Epoch [44/50], Loss: 0.3527, Time: 0.25s\n",
            "Epoch [45/50], Loss: 0.3719, Time: 0.26s\n",
            "Epoch [46/50], Loss: 0.3270, Time: 0.24s\n",
            "Epoch [47/50], Loss: 0.3438, Time: 0.26s\n",
            "Epoch [48/50], Loss: 0.3418, Time: 0.25s\n",
            "Epoch [49/50], Loss: 0.3271, Time: 0.25s\n",
            "Epoch [50/50], Loss: 0.3295, Time: 0.25s\n",
            "\n",
            "Training with Parameters: Hidden Layers=[8], Activation=relu, LR=0.01, Batch Size=32, Epochs=50, Dropout=0.2, L2=0.0001\n",
            "Epoch [1/50], Loss: 0.5280, Time: 0.26s\n",
            "Epoch [2/50], Loss: 0.3847, Time: 0.25s\n",
            "Epoch [3/50], Loss: 0.3358, Time: 0.27s\n",
            "Epoch [4/50], Loss: 0.3492, Time: 0.27s\n",
            "Epoch [5/50], Loss: 0.3273, Time: 0.26s\n",
            "Epoch [6/50], Loss: 0.3181, Time: 0.26s\n",
            "Epoch [7/50], Loss: 0.3072, Time: 0.27s\n",
            "Epoch [8/50], Loss: 0.3151, Time: 0.27s\n",
            "Epoch [9/50], Loss: 0.3247, Time: 0.28s\n",
            "Epoch [10/50], Loss: 0.3094, Time: 0.25s\n",
            "Epoch [11/50], Loss: 0.3036, Time: 0.25s\n",
            "Epoch [12/50], Loss: 0.3248, Time: 0.25s\n",
            "Epoch [13/50], Loss: 0.3081, Time: 0.25s\n",
            "Epoch [14/50], Loss: 0.2891, Time: 0.25s\n",
            "Epoch [15/50], Loss: 0.2962, Time: 0.25s\n",
            "Epoch [16/50], Loss: 0.2973, Time: 0.25s\n",
            "Epoch [17/50], Loss: 0.2953, Time: 0.25s\n",
            "Epoch [18/50], Loss: 0.2882, Time: 0.25s\n",
            "Epoch [19/50], Loss: 0.2919, Time: 0.25s\n",
            "Epoch [20/50], Loss: 0.3068, Time: 0.25s\n",
            "Epoch [21/50], Loss: 0.2797, Time: 0.25s\n",
            "Epoch [22/50], Loss: 0.2896, Time: 0.25s\n",
            "Epoch [23/50], Loss: 0.2901, Time: 0.25s\n",
            "Epoch [24/50], Loss: 0.3206, Time: 0.25s\n",
            "Epoch [25/50], Loss: 0.2844, Time: 0.26s\n",
            "Epoch [26/50], Loss: 0.2888, Time: 0.25s\n",
            "Epoch [27/50], Loss: 0.3214, Time: 0.25s\n",
            "Epoch [28/50], Loss: 0.2751, Time: 0.25s\n",
            "Epoch [29/50], Loss: 0.2919, Time: 0.26s\n",
            "Epoch [30/50], Loss: 0.2815, Time: 0.25s\n",
            "Epoch [31/50], Loss: 0.2690, Time: 0.25s\n",
            "Epoch [32/50], Loss: 0.2912, Time: 0.25s\n",
            "Epoch [33/50], Loss: 0.2935, Time: 0.26s\n",
            "Epoch [34/50], Loss: 0.2913, Time: 0.51s\n",
            "Epoch [35/50], Loss: 0.2956, Time: 0.25s\n",
            "Epoch [36/50], Loss: 0.2797, Time: 0.25s\n",
            "Epoch [37/50], Loss: 0.2853, Time: 0.26s\n",
            "Epoch [38/50], Loss: 0.2892, Time: 0.25s\n",
            "Epoch [39/50], Loss: 0.3171, Time: 0.26s\n",
            "Epoch [40/50], Loss: 0.2705, Time: 0.26s\n",
            "Epoch [41/50], Loss: 0.2908, Time: 0.26s\n",
            "Epoch [42/50], Loss: 0.2920, Time: 0.25s\n",
            "Epoch [43/50], Loss: 0.2688, Time: 0.25s\n",
            "Epoch [44/50], Loss: 0.2832, Time: 0.27s\n",
            "Epoch [45/50], Loss: 0.2829, Time: 0.26s\n",
            "Epoch [46/50], Loss: 0.2888, Time: 0.25s\n",
            "Epoch [47/50], Loss: 0.3127, Time: 0.26s\n",
            "Epoch [48/50], Loss: 0.3010, Time: 0.26s\n",
            "Epoch [49/50], Loss: 0.2856, Time: 0.27s\n",
            "Epoch [50/50], Loss: 0.2786, Time: 0.25s\n",
            "\n",
            "Training with Parameters: Hidden Layers=[16], Activation=relu, LR=0.01, Batch Size=32, Epochs=50, Dropout=0.2, L2=0.0001\n",
            "Epoch [1/50], Loss: 0.5229, Time: 0.27s\n",
            "Epoch [2/50], Loss: 0.3597, Time: 0.28s\n",
            "Epoch [3/50], Loss: 0.3484, Time: 0.28s\n",
            "Epoch [4/50], Loss: 0.3360, Time: 0.26s\n",
            "Epoch [5/50], Loss: 0.3257, Time: 0.25s\n",
            "Epoch [6/50], Loss: 0.3141, Time: 0.26s\n",
            "Epoch [7/50], Loss: 0.3067, Time: 0.27s\n",
            "Epoch [8/50], Loss: 0.2915, Time: 0.25s\n",
            "Epoch [9/50], Loss: 0.2809, Time: 0.26s\n",
            "Epoch [10/50], Loss: 0.2872, Time: 0.27s\n",
            "Epoch [11/50], Loss: 0.2819, Time: 0.25s\n",
            "Epoch [12/50], Loss: 0.2933, Time: 0.25s\n",
            "Epoch [13/50], Loss: 0.2958, Time: 0.26s\n",
            "Epoch [14/50], Loss: 0.2697, Time: 0.26s\n",
            "Epoch [15/50], Loss: 0.2547, Time: 0.25s\n",
            "Epoch [16/50], Loss: 0.2584, Time: 0.27s\n",
            "Epoch [17/50], Loss: 0.2822, Time: 0.25s\n",
            "Epoch [18/50], Loss: 0.3021, Time: 0.26s\n",
            "Epoch [19/50], Loss: 0.2694, Time: 0.26s\n",
            "Epoch [20/50], Loss: 0.2383, Time: 0.25s\n",
            "Epoch [21/50], Loss: 0.2629, Time: 0.26s\n",
            "Epoch [22/50], Loss: 0.2869, Time: 0.25s\n",
            "Epoch [23/50], Loss: 0.2671, Time: 0.25s\n",
            "Epoch [24/50], Loss: 0.2545, Time: 0.26s\n",
            "Epoch [25/50], Loss: 0.2497, Time: 0.25s\n",
            "Epoch [26/50], Loss: 0.2592, Time: 0.27s\n",
            "Epoch [27/50], Loss: 0.2440, Time: 0.25s\n",
            "Epoch [28/50], Loss: 0.2550, Time: 0.25s\n",
            "Epoch [29/50], Loss: 0.3036, Time: 0.26s\n",
            "Epoch [30/50], Loss: 0.2731, Time: 0.26s\n",
            "Epoch [31/50], Loss: 0.2430, Time: 0.25s\n",
            "Epoch [32/50], Loss: 0.2511, Time: 0.26s\n",
            "Epoch [33/50], Loss: 0.2464, Time: 0.26s\n",
            "Epoch [34/50], Loss: 0.2513, Time: 0.25s\n",
            "Epoch [35/50], Loss: 0.2427, Time: 0.26s\n",
            "Epoch [36/50], Loss: 0.2517, Time: 0.25s\n",
            "Epoch [37/50], Loss: 0.2281, Time: 0.26s\n",
            "Epoch [38/50], Loss: 0.2337, Time: 0.26s\n",
            "Epoch [39/50], Loss: 0.2685, Time: 0.25s\n",
            "Epoch [40/50], Loss: 0.2709, Time: 0.25s\n",
            "Epoch [41/50], Loss: 0.2597, Time: 0.26s\n",
            "Epoch [42/50], Loss: 0.2421, Time: 0.25s\n",
            "Epoch [43/50], Loss: 0.2474, Time: 0.26s\n",
            "Epoch [44/50], Loss: 0.2336, Time: 0.27s\n",
            "Epoch [45/50], Loss: 0.2302, Time: 0.27s\n",
            "Epoch [46/50], Loss: 0.2654, Time: 0.27s\n",
            "Epoch [47/50], Loss: 0.2501, Time: 0.28s\n",
            "Epoch [48/50], Loss: 0.2441, Time: 0.27s\n",
            "Epoch [49/50], Loss: 0.2330, Time: 0.29s\n",
            "Epoch [50/50], Loss: 0.2273, Time: 0.26s\n",
            "\n",
            "Training with Parameters: Hidden Layers=[32], Activation=relu, LR=0.01, Batch Size=32, Epochs=50, Dropout=0.2, L2=0.0001\n",
            "Epoch [1/50], Loss: 0.4348, Time: 0.26s\n",
            "Epoch [2/50], Loss: 0.3322, Time: 0.26s\n",
            "Epoch [3/50], Loss: 0.3259, Time: 0.26s\n",
            "Epoch [4/50], Loss: 0.3181, Time: 0.26s\n",
            "Epoch [5/50], Loss: 0.2921, Time: 0.26s\n",
            "Epoch [6/50], Loss: 0.2890, Time: 0.29s\n",
            "Epoch [7/50], Loss: 0.2613, Time: 0.26s\n",
            "Epoch [8/50], Loss: 0.2787, Time: 0.27s\n",
            "Epoch [9/50], Loss: 0.2634, Time: 0.25s\n",
            "Epoch [10/50], Loss: 0.2729, Time: 0.26s\n",
            "Epoch [11/50], Loss: 0.2395, Time: 0.26s\n",
            "Epoch [12/50], Loss: 0.2503, Time: 0.25s\n",
            "Epoch [13/50], Loss: 0.2365, Time: 0.25s\n",
            "Epoch [14/50], Loss: 0.2349, Time: 0.26s\n",
            "Epoch [15/50], Loss: 0.2661, Time: 0.25s\n",
            "Epoch [16/50], Loss: 0.2412, Time: 0.25s\n",
            "Epoch [17/50], Loss: 0.2164, Time: 0.26s\n",
            "Epoch [18/50], Loss: 0.2002, Time: 0.25s\n",
            "Epoch [19/50], Loss: 0.2172, Time: 0.28s\n",
            "Epoch [20/50], Loss: 0.1971, Time: 0.26s\n",
            "Epoch [21/50], Loss: 0.2354, Time: 0.27s\n",
            "Epoch [22/50], Loss: 0.2100, Time: 0.26s\n",
            "Epoch [23/50], Loss: 0.2513, Time: 0.26s\n",
            "Epoch [24/50], Loss: 0.2005, Time: 0.25s\n",
            "Epoch [25/50], Loss: 0.1935, Time: 0.25s\n",
            "Epoch [26/50], Loss: 0.1814, Time: 0.26s\n",
            "Epoch [27/50], Loss: 0.1656, Time: 0.26s\n",
            "Epoch [28/50], Loss: 0.1839, Time: 0.26s\n",
            "Epoch [29/50], Loss: 0.2155, Time: 0.26s\n",
            "Epoch [30/50], Loss: 0.2030, Time: 0.26s\n",
            "Epoch [31/50], Loss: 0.1938, Time: 0.27s\n",
            "Epoch [32/50], Loss: 0.2149, Time: 0.25s\n",
            "Epoch [33/50], Loss: 0.1790, Time: 0.29s\n",
            "Epoch [34/50], Loss: 0.1851, Time: 0.26s\n",
            "Epoch [35/50], Loss: 0.1939, Time: 0.25s\n",
            "Epoch [36/50], Loss: 0.1833, Time: 0.25s\n",
            "Epoch [37/50], Loss: 0.1662, Time: 0.28s\n",
            "Epoch [38/50], Loss: 0.1722, Time: 0.29s\n",
            "Epoch [39/50], Loss: 0.1618, Time: 0.28s\n",
            "Epoch [40/50], Loss: 0.1844, Time: 0.27s\n",
            "Epoch [41/50], Loss: 0.1685, Time: 0.29s\n",
            "Epoch [42/50], Loss: 0.2007, Time: 0.29s\n",
            "Epoch [43/50], Loss: 0.1639, Time: 0.28s\n",
            "Epoch [44/50], Loss: 0.1860, Time: 0.28s\n",
            "Epoch [45/50], Loss: 0.1742, Time: 0.26s\n",
            "Epoch [46/50], Loss: 0.1702, Time: 0.26s\n",
            "Epoch [47/50], Loss: 0.1591, Time: 0.26s\n",
            "Epoch [48/50], Loss: 0.1366, Time: 0.26s\n",
            "Epoch [49/50], Loss: 0.1703, Time: 0.27s\n",
            "Epoch [50/50], Loss: 0.1479, Time: 0.26s\n",
            "\n",
            "Training with Parameters: Hidden Layers=[64], Activation=relu, LR=0.01, Batch Size=32, Epochs=50, Dropout=0.2, L2=0.0001\n",
            "Epoch [1/50], Loss: 0.3935, Time: 0.27s\n",
            "Epoch [2/50], Loss: 0.3081, Time: 0.26s\n",
            "Epoch [3/50], Loss: 0.2982, Time: 0.26s\n",
            "Epoch [4/50], Loss: 0.2731, Time: 0.26s\n",
            "Epoch [5/50], Loss: 0.2739, Time: 0.28s\n",
            "Epoch [6/50], Loss: 0.2312, Time: 0.26s\n",
            "Epoch [7/50], Loss: 0.2222, Time: 0.26s\n",
            "Epoch [8/50], Loss: 0.2088, Time: 0.26s\n",
            "Epoch [9/50], Loss: 0.2250, Time: 0.26s\n",
            "Epoch [10/50], Loss: 0.2421, Time: 0.26s\n",
            "Epoch [11/50], Loss: 0.2043, Time: 0.26s\n",
            "Epoch [12/50], Loss: 0.1981, Time: 0.27s\n",
            "Epoch [13/50], Loss: 0.2019, Time: 0.26s\n",
            "Epoch [14/50], Loss: 0.2211, Time: 0.25s\n",
            "Epoch [15/50], Loss: 0.1922, Time: 0.26s\n",
            "Epoch [16/50], Loss: 0.1826, Time: 0.26s\n",
            "Epoch [17/50], Loss: 0.2208, Time: 0.26s\n",
            "Epoch [18/50], Loss: 0.1971, Time: 0.26s\n",
            "Epoch [19/50], Loss: 0.1937, Time: 0.26s\n",
            "Epoch [20/50], Loss: 0.1927, Time: 0.26s\n",
            "Epoch [21/50], Loss: 0.1803, Time: 0.27s\n",
            "Epoch [22/50], Loss: 0.1742, Time: 0.27s\n",
            "Epoch [23/50], Loss: 0.1898, Time: 0.26s\n",
            "Epoch [24/50], Loss: 0.1598, Time: 0.26s\n",
            "Epoch [25/50], Loss: 0.1729, Time: 0.27s\n",
            "Epoch [26/50], Loss: 0.1638, Time: 0.26s\n",
            "Epoch [27/50], Loss: 0.1392, Time: 0.27s\n",
            "Epoch [28/50], Loss: 0.1517, Time: 0.26s\n",
            "Epoch [29/50], Loss: 0.1502, Time: 0.27s\n",
            "Epoch [30/50], Loss: 0.1712, Time: 0.25s\n",
            "Epoch [31/50], Loss: 0.1650, Time: 0.26s\n",
            "Epoch [32/50], Loss: 0.1742, Time: 0.30s\n",
            "Epoch [33/50], Loss: 0.1738, Time: 0.27s\n",
            "Epoch [34/50], Loss: 0.1423, Time: 0.28s\n",
            "Epoch [35/50], Loss: 0.1832, Time: 0.29s\n",
            "Epoch [36/50], Loss: 0.1797, Time: 0.27s\n",
            "Epoch [37/50], Loss: 0.1540, Time: 0.29s\n",
            "Epoch [38/50], Loss: 0.1467, Time: 0.27s\n",
            "Epoch [39/50], Loss: 0.2048, Time: 0.26s\n",
            "Epoch [40/50], Loss: 0.1416, Time: 0.26s\n",
            "Epoch [41/50], Loss: 0.1767, Time: 0.26s\n",
            "Epoch [42/50], Loss: 0.1375, Time: 0.26s\n",
            "Epoch [43/50], Loss: 0.1286, Time: 0.26s\n",
            "Epoch [44/50], Loss: 0.1607, Time: 0.26s\n",
            "Epoch [45/50], Loss: 0.1390, Time: 0.26s\n",
            "Epoch [46/50], Loss: 0.1384, Time: 0.25s\n",
            "Epoch [47/50], Loss: 0.1283, Time: 0.26s\n",
            "Epoch [48/50], Loss: 0.1433, Time: 0.27s\n",
            "Epoch [49/50], Loss: 0.1277, Time: 0.27s\n",
            "Epoch [50/50], Loss: 0.1512, Time: 0.28s\n",
            "\n",
            "Training with Parameters: Hidden Layers=[4, 4], Activation=relu, LR=0.01, Batch Size=32, Epochs=50, Dropout=0.2, L2=0.0001\n",
            "Epoch [1/50], Loss: 0.6455, Time: 0.27s\n",
            "Epoch [2/50], Loss: 0.5384, Time: 0.26s\n",
            "Epoch [3/50], Loss: 0.4342, Time: 0.27s\n",
            "Epoch [4/50], Loss: 0.4318, Time: 0.28s\n",
            "Epoch [5/50], Loss: 0.4155, Time: 0.27s\n",
            "Epoch [6/50], Loss: 0.3814, Time: 0.26s\n",
            "Epoch [7/50], Loss: 0.4099, Time: 0.28s\n",
            "Epoch [8/50], Loss: 0.4000, Time: 0.27s\n",
            "Epoch [9/50], Loss: 0.3994, Time: 0.27s\n",
            "Epoch [10/50], Loss: 0.3698, Time: 0.27s\n",
            "Epoch [11/50], Loss: 0.3696, Time: 0.27s\n",
            "Epoch [12/50], Loss: 0.3930, Time: 0.28s\n",
            "Epoch [13/50], Loss: 0.3805, Time: 0.28s\n",
            "Epoch [14/50], Loss: 0.3671, Time: 0.28s\n",
            "Epoch [15/50], Loss: 0.3571, Time: 0.27s\n",
            "Epoch [16/50], Loss: 0.3855, Time: 0.28s\n",
            "Epoch [17/50], Loss: 0.4149, Time: 0.26s\n",
            "Epoch [18/50], Loss: 0.3884, Time: 0.27s\n",
            "Epoch [19/50], Loss: 0.3579, Time: 0.27s\n",
            "Epoch [20/50], Loss: 0.3826, Time: 0.27s\n",
            "Epoch [21/50], Loss: 0.3750, Time: 0.27s\n",
            "Epoch [22/50], Loss: 0.3955, Time: 0.28s\n",
            "Epoch [23/50], Loss: 0.3680, Time: 0.28s\n",
            "Epoch [24/50], Loss: 0.3773, Time: 0.28s\n",
            "Epoch [25/50], Loss: 0.3761, Time: 0.29s\n",
            "Epoch [26/50], Loss: 0.3794, Time: 0.29s\n",
            "Epoch [27/50], Loss: 0.4009, Time: 0.29s\n",
            "Epoch [28/50], Loss: 0.3654, Time: 0.30s\n",
            "Epoch [29/50], Loss: 0.3621, Time: 0.30s\n",
            "Epoch [30/50], Loss: 0.3792, Time: 0.29s\n",
            "Epoch [31/50], Loss: 0.3718, Time: 0.27s\n",
            "Epoch [32/50], Loss: 0.3719, Time: 0.28s\n",
            "Epoch [33/50], Loss: 0.3799, Time: 0.27s\n",
            "Epoch [34/50], Loss: 0.3833, Time: 0.27s\n",
            "Epoch [35/50], Loss: 0.3387, Time: 0.28s\n",
            "Epoch [36/50], Loss: 0.3531, Time: 0.26s\n",
            "Epoch [37/50], Loss: 0.3790, Time: 0.27s\n",
            "Epoch [38/50], Loss: 0.3669, Time: 0.27s\n",
            "Epoch [39/50], Loss: 0.3648, Time: 0.27s\n",
            "Epoch [40/50], Loss: 0.3747, Time: 0.27s\n",
            "Epoch [41/50], Loss: 0.3684, Time: 0.27s\n",
            "Epoch [42/50], Loss: 0.3981, Time: 0.27s\n",
            "Epoch [43/50], Loss: 0.3400, Time: 0.27s\n",
            "Epoch [44/50], Loss: 0.3357, Time: 0.27s\n",
            "Epoch [45/50], Loss: 0.3998, Time: 0.27s\n",
            "Epoch [46/50], Loss: 0.3725, Time: 0.27s\n",
            "Epoch [47/50], Loss: 0.3849, Time: 0.28s\n",
            "Epoch [48/50], Loss: 0.3703, Time: 0.27s\n",
            "Epoch [49/50], Loss: 0.3543, Time: 0.27s\n",
            "Epoch [50/50], Loss: 0.3582, Time: 0.28s\n",
            "\n",
            "Training with Parameters: Hidden Layers=[8, 8], Activation=relu, LR=0.01, Batch Size=32, Epochs=50, Dropout=0.2, L2=0.0001\n",
            "Epoch [1/50], Loss: 0.6057, Time: 0.28s\n",
            "Epoch [2/50], Loss: 0.4587, Time: 0.28s\n",
            "Epoch [3/50], Loss: 0.4120, Time: 0.28s\n",
            "Epoch [4/50], Loss: 0.3788, Time: 0.27s\n",
            "Epoch [5/50], Loss: 0.3636, Time: 0.28s\n",
            "Epoch [6/50], Loss: 0.3501, Time: 0.28s\n",
            "Epoch [7/50], Loss: 0.3452, Time: 0.28s\n",
            "Epoch [8/50], Loss: 0.3584, Time: 0.27s\n",
            "Epoch [9/50], Loss: 0.3464, Time: 0.27s\n",
            "Epoch [10/50], Loss: 0.3271, Time: 0.28s\n",
            "Epoch [11/50], Loss: 0.3206, Time: 0.28s\n",
            "Epoch [12/50], Loss: 0.3209, Time: 0.29s\n",
            "Epoch [13/50], Loss: 0.3250, Time: 0.27s\n",
            "Epoch [14/50], Loss: 0.3252, Time: 0.27s\n",
            "Epoch [15/50], Loss: 0.3441, Time: 0.27s\n",
            "Epoch [16/50], Loss: 0.3198, Time: 0.29s\n",
            "Epoch [17/50], Loss: 0.3368, Time: 0.30s\n",
            "Epoch [18/50], Loss: 0.3272, Time: 0.28s\n",
            "Epoch [19/50], Loss: 0.3103, Time: 0.28s\n",
            "Epoch [20/50], Loss: 0.3211, Time: 0.29s\n",
            "Epoch [21/50], Loss: 0.3156, Time: 0.30s\n",
            "Epoch [22/50], Loss: 0.3376, Time: 0.30s\n",
            "Epoch [23/50], Loss: 0.3065, Time: 0.27s\n",
            "Epoch [24/50], Loss: 0.3272, Time: 0.28s\n",
            "Epoch [25/50], Loss: 0.2739, Time: 0.27s\n",
            "Epoch [26/50], Loss: 0.3146, Time: 0.28s\n",
            "Epoch [27/50], Loss: 0.2940, Time: 0.27s\n",
            "Epoch [28/50], Loss: 0.2749, Time: 0.28s\n",
            "Epoch [29/50], Loss: 0.2744, Time: 0.27s\n",
            "Epoch [30/50], Loss: 0.3201, Time: 0.27s\n",
            "Epoch [31/50], Loss: 0.2999, Time: 0.28s\n",
            "Epoch [32/50], Loss: 0.2881, Time: 0.29s\n",
            "Epoch [33/50], Loss: 0.2892, Time: 0.28s\n",
            "Epoch [34/50], Loss: 0.2669, Time: 0.27s\n",
            "Epoch [35/50], Loss: 0.3014, Time: 0.27s\n",
            "Epoch [36/50], Loss: 0.3414, Time: 0.27s\n",
            "Epoch [37/50], Loss: 0.3006, Time: 0.28s\n",
            "Epoch [38/50], Loss: 0.2811, Time: 0.27s\n",
            "Epoch [39/50], Loss: 0.2842, Time: 0.28s\n",
            "Epoch [40/50], Loss: 0.3128, Time: 0.29s\n",
            "Epoch [41/50], Loss: 0.2946, Time: 0.27s\n",
            "Epoch [42/50], Loss: 0.3111, Time: 0.28s\n",
            "Epoch [43/50], Loss: 0.2803, Time: 0.29s\n",
            "Epoch [44/50], Loss: 0.2748, Time: 0.27s\n",
            "Epoch [45/50], Loss: 0.2544, Time: 0.28s\n",
            "Epoch [46/50], Loss: 0.2671, Time: 0.28s\n",
            "Epoch [47/50], Loss: 0.2892, Time: 0.28s\n",
            "Epoch [48/50], Loss: 0.2296, Time: 0.27s\n",
            "Epoch [49/50], Loss: 0.2519, Time: 0.28s\n",
            "Epoch [50/50], Loss: 0.2638, Time: 0.26s\n",
            "\n",
            "Training with Parameters: Hidden Layers=[16, 16], Activation=relu, LR=0.01, Batch Size=32, Epochs=50, Dropout=0.2, L2=0.0001\n",
            "Epoch [1/50], Loss: 0.5074, Time: 0.29s\n",
            "Epoch [2/50], Loss: 0.3737, Time: 0.28s\n",
            "Epoch [3/50], Loss: 0.3499, Time: 0.28s\n",
            "Epoch [4/50], Loss: 0.3394, Time: 0.27s\n",
            "Epoch [5/50], Loss: 0.3202, Time: 0.27s\n",
            "Epoch [6/50], Loss: 0.3317, Time: 0.28s\n",
            "Epoch [7/50], Loss: 0.3091, Time: 0.27s\n",
            "Epoch [8/50], Loss: 0.3086, Time: 0.29s\n",
            "Epoch [9/50], Loss: 0.3144, Time: 0.30s\n",
            "Epoch [10/50], Loss: 0.3160, Time: 0.29s\n",
            "Epoch [11/50], Loss: 0.2977, Time: 0.28s\n",
            "Epoch [12/50], Loss: 0.2873, Time: 0.29s\n",
            "Epoch [13/50], Loss: 0.2860, Time: 0.32s\n",
            "Epoch [14/50], Loss: 0.2722, Time: 0.29s\n",
            "Epoch [15/50], Loss: 0.2750, Time: 0.29s\n",
            "Epoch [16/50], Loss: 0.2693, Time: 0.27s\n",
            "Epoch [17/50], Loss: 0.2487, Time: 0.27s\n",
            "Epoch [18/50], Loss: 0.2871, Time: 0.28s\n",
            "Epoch [19/50], Loss: 0.2470, Time: 0.28s\n",
            "Epoch [20/50], Loss: 0.2448, Time: 0.26s\n",
            "Epoch [21/50], Loss: 0.2406, Time: 0.28s\n",
            "Epoch [22/50], Loss: 0.2797, Time: 0.28s\n",
            "Epoch [23/50], Loss: 0.2550, Time: 0.28s\n",
            "Epoch [24/50], Loss: 0.2409, Time: 0.28s\n",
            "Epoch [25/50], Loss: 0.2702, Time: 0.28s\n",
            "Epoch [26/50], Loss: 0.2332, Time: 0.27s\n",
            "Epoch [27/50], Loss: 0.2540, Time: 0.29s\n",
            "Epoch [28/50], Loss: 0.2386, Time: 0.29s\n",
            "Epoch [29/50], Loss: 0.2316, Time: 0.33s\n",
            "Epoch [30/50], Loss: 0.2722, Time: 0.29s\n",
            "Epoch [31/50], Loss: 0.2440, Time: 0.27s\n",
            "Epoch [32/50], Loss: 0.2346, Time: 0.29s\n",
            "Epoch [33/50], Loss: 0.2410, Time: 0.28s\n",
            "Epoch [34/50], Loss: 0.2404, Time: 0.28s\n",
            "Epoch [35/50], Loss: 0.2311, Time: 0.27s\n",
            "Epoch [36/50], Loss: 0.2207, Time: 0.27s\n",
            "Epoch [37/50], Loss: 0.2308, Time: 0.27s\n",
            "Epoch [38/50], Loss: 0.2520, Time: 0.28s\n",
            "Epoch [39/50], Loss: 0.2268, Time: 0.29s\n",
            "Epoch [40/50], Loss: 0.2091, Time: 0.27s\n",
            "Epoch [41/50], Loss: 0.2526, Time: 0.29s\n",
            "Epoch [42/50], Loss: 0.2246, Time: 0.28s\n",
            "Epoch [43/50], Loss: 0.2479, Time: 0.29s\n",
            "Epoch [44/50], Loss: 0.2289, Time: 0.27s\n",
            "Epoch [45/50], Loss: 0.2068, Time: 0.28s\n",
            "Epoch [46/50], Loss: 0.2424, Time: 0.29s\n",
            "Epoch [47/50], Loss: 0.2268, Time: 0.27s\n",
            "Epoch [48/50], Loss: 0.2137, Time: 0.28s\n",
            "Epoch [49/50], Loss: 0.1890, Time: 0.28s\n",
            "Epoch [50/50], Loss: 0.1997, Time: 0.29s\n",
            "\n",
            "Training with Parameters: Hidden Layers=[32, 16, 8], Activation=relu, LR=0.01, Batch Size=32, Epochs=50, Dropout=0.2, L2=0.0001\n",
            "Epoch [1/50], Loss: 0.5472, Time: 0.29s\n",
            "Epoch [2/50], Loss: 0.4033, Time: 0.31s\n",
            "Epoch [3/50], Loss: 0.3288, Time: 0.33s\n",
            "Epoch [4/50], Loss: 0.3141, Time: 0.32s\n",
            "Epoch [5/50], Loss: 0.3364, Time: 0.28s\n",
            "Epoch [6/50], Loss: 0.3282, Time: 0.29s\n",
            "Epoch [7/50], Loss: 0.3148, Time: 0.28s\n",
            "Epoch [8/50], Loss: 0.2744, Time: 0.28s\n",
            "Epoch [9/50], Loss: 0.2875, Time: 0.30s\n",
            "Epoch [10/50], Loss: 0.2937, Time: 0.29s\n",
            "Epoch [11/50], Loss: 0.2653, Time: 0.29s\n",
            "Epoch [12/50], Loss: 0.2313, Time: 0.28s\n",
            "Epoch [13/50], Loss: 0.2462, Time: 0.29s\n",
            "Epoch [14/50], Loss: 0.2855, Time: 0.29s\n",
            "Epoch [15/50], Loss: 0.2640, Time: 0.29s\n",
            "Epoch [16/50], Loss: 0.2623, Time: 0.31s\n",
            "Epoch [17/50], Loss: 0.2364, Time: 0.30s\n",
            "Epoch [18/50], Loss: 0.2486, Time: 0.28s\n",
            "Epoch [19/50], Loss: 0.2430, Time: 0.29s\n",
            "Epoch [20/50], Loss: 0.2395, Time: 0.29s\n",
            "Epoch [21/50], Loss: 0.2445, Time: 0.29s\n",
            "Epoch [22/50], Loss: 0.2625, Time: 0.29s\n",
            "Epoch [23/50], Loss: 0.2594, Time: 0.28s\n",
            "Epoch [24/50], Loss: 0.2230, Time: 0.28s\n",
            "Epoch [25/50], Loss: 0.2282, Time: 0.30s\n",
            "Epoch [26/50], Loss: 0.2240, Time: 0.28s\n",
            "Epoch [27/50], Loss: 0.1897, Time: 0.29s\n",
            "Epoch [28/50], Loss: 0.2381, Time: 0.29s\n",
            "Epoch [29/50], Loss: 0.2064, Time: 0.28s\n",
            "Epoch [30/50], Loss: 0.1907, Time: 0.29s\n",
            "Epoch [31/50], Loss: 0.2278, Time: 0.30s\n",
            "Epoch [32/50], Loss: 0.2012, Time: 0.30s\n",
            "Epoch [33/50], Loss: 0.1859, Time: 0.30s\n",
            "Epoch [34/50], Loss: 0.1973, Time: 0.30s\n",
            "Epoch [35/50], Loss: 0.1981, Time: 0.29s\n",
            "Epoch [36/50], Loss: 0.1866, Time: 0.30s\n",
            "Epoch [37/50], Loss: 0.2354, Time: 0.29s\n",
            "Epoch [38/50], Loss: 0.1799, Time: 0.28s\n",
            "Epoch [39/50], Loss: 0.1911, Time: 0.30s\n",
            "Epoch [40/50], Loss: 0.2016, Time: 0.31s\n",
            "Epoch [41/50], Loss: 0.1908, Time: 0.29s\n",
            "Epoch [42/50], Loss: 0.2168, Time: 0.30s\n",
            "Epoch [43/50], Loss: 0.2167, Time: 0.31s\n",
            "Epoch [44/50], Loss: 0.2360, Time: 0.31s\n",
            "Epoch [45/50], Loss: 0.2080, Time: 0.28s\n",
            "Epoch [46/50], Loss: 0.1891, Time: 0.29s\n",
            "Epoch [47/50], Loss: 0.1920, Time: 0.29s\n",
            "Epoch [48/50], Loss: 0.1598, Time: 0.29s\n",
            "Epoch [49/50], Loss: 0.2081, Time: 0.31s\n",
            "Epoch [50/50], Loss: 0.1769, Time: 0.30s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Bandingkan jumlah hidden layers dan jumlah neuron.\n",
        "\n"
      ],
      "metadata": {
        "id": "hxsd0JKYo2uq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Eksperimen 2: Activation Functions**\n"
      ],
      "metadata": {
        "id": "eAigHZZ8o4OH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 2: Comparing Activation Functions\n",
        "activation_functions = ['linear', 'sigmoid', 'relu', 'softmax', 'tanh']\n",
        "results_activation_functions = []\n",
        "for activation_fn in activation_functions:\n",
        "    accuracy = train_and_evaluate(hidden_layers=[32], activation_fn=activation_fn, learning_rate=0.01, batch_size=32, epochs=50, dropout_rate=0.2, weight_decay=1e-4)\n",
        "    results_activation_functions.append({'activation_function': activation_fn, 'accuracy': accuracy})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQv_JUWIo5pH",
        "outputId": "9ddb36fe-b815-4ec3-dd33-aea9e79e0f41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training with Parameters: Hidden Layers=[32], Activation=linear, LR=0.01, Batch Size=32, Epochs=50, Dropout=0.2, L2=0.0001\n",
            "Epoch [1/50], Loss: 0.4222, Time: 0.28s\n",
            "Epoch [2/50], Loss: 0.3719, Time: 0.28s\n",
            "Epoch [3/50], Loss: 0.3800, Time: 0.27s\n",
            "Epoch [4/50], Loss: 0.3533, Time: 0.27s\n",
            "Epoch [5/50], Loss: 0.3550, Time: 0.27s\n",
            "Epoch [6/50], Loss: 0.3539, Time: 0.27s\n",
            "Epoch [7/50], Loss: 0.3600, Time: 0.28s\n",
            "Epoch [8/50], Loss: 0.3537, Time: 0.27s\n",
            "Epoch [9/50], Loss: 0.3639, Time: 0.28s\n",
            "Epoch [10/50], Loss: 0.3494, Time: 0.27s\n",
            "Epoch [11/50], Loss: 0.3579, Time: 0.28s\n",
            "Epoch [12/50], Loss: 0.3631, Time: 0.27s\n",
            "Epoch [13/50], Loss: 0.3674, Time: 0.28s\n",
            "Epoch [14/50], Loss: 0.3594, Time: 0.27s\n",
            "Epoch [15/50], Loss: 0.3697, Time: 0.27s\n",
            "Epoch [16/50], Loss: 0.3712, Time: 0.28s\n",
            "Epoch [17/50], Loss: 0.3579, Time: 0.27s\n",
            "Epoch [18/50], Loss: 0.3663, Time: 0.26s\n",
            "Epoch [19/50], Loss: 0.3503, Time: 0.27s\n",
            "Epoch [20/50], Loss: 0.3750, Time: 0.27s\n",
            "Epoch [21/50], Loss: 0.3540, Time: 0.27s\n",
            "Epoch [22/50], Loss: 0.3661, Time: 0.27s\n",
            "Epoch [23/50], Loss: 0.3461, Time: 0.28s\n",
            "Epoch [24/50], Loss: 0.3532, Time: 0.28s\n",
            "Epoch [25/50], Loss: 0.3418, Time: 0.28s\n",
            "Epoch [26/50], Loss: 0.3572, Time: 0.27s\n",
            "Epoch [27/50], Loss: 0.3593, Time: 0.30s\n",
            "Epoch [28/50], Loss: 0.3794, Time: 0.27s\n",
            "Epoch [29/50], Loss: 0.3519, Time: 0.29s\n",
            "Epoch [30/50], Loss: 0.3521, Time: 0.30s\n",
            "Epoch [31/50], Loss: 0.3415, Time: 0.29s\n",
            "Epoch [32/50], Loss: 0.3571, Time: 0.29s\n",
            "Epoch [33/50], Loss: 0.3459, Time: 0.30s\n",
            "Epoch [34/50], Loss: 0.3532, Time: 0.30s\n",
            "Epoch [35/50], Loss: 0.3565, Time: 0.29s\n",
            "Epoch [36/50], Loss: 0.3493, Time: 0.29s\n",
            "Epoch [37/50], Loss: 0.3690, Time: 0.26s\n",
            "Epoch [38/50], Loss: 0.3584, Time: 0.28s\n",
            "Epoch [39/50], Loss: 0.3500, Time: 0.27s\n",
            "Epoch [40/50], Loss: 0.3527, Time: 0.28s\n",
            "Epoch [41/50], Loss: 0.3641, Time: 0.27s\n",
            "Epoch [42/50], Loss: 0.3456, Time: 0.29s\n",
            "Epoch [43/50], Loss: 0.3598, Time: 0.28s\n",
            "Epoch [44/50], Loss: 0.3477, Time: 0.27s\n",
            "Epoch [45/50], Loss: 0.3528, Time: 0.27s\n",
            "Epoch [46/50], Loss: 0.3562, Time: 0.27s\n",
            "Epoch [47/50], Loss: 0.3649, Time: 0.29s\n",
            "Epoch [48/50], Loss: 0.3565, Time: 0.27s\n",
            "Epoch [49/50], Loss: 0.3561, Time: 0.29s\n",
            "Epoch [50/50], Loss: 0.3391, Time: 0.28s\n",
            "\n",
            "Training with Parameters: Hidden Layers=[32], Activation=sigmoid, LR=0.01, Batch Size=32, Epochs=50, Dropout=0.2, L2=0.0001\n",
            "Epoch [1/50], Loss: 0.5185, Time: 0.28s\n",
            "Epoch [2/50], Loss: 0.3812, Time: 0.29s\n",
            "Epoch [3/50], Loss: 0.3894, Time: 0.28s\n",
            "Epoch [4/50], Loss: 0.3589, Time: 0.29s\n",
            "Epoch [5/50], Loss: 0.3509, Time: 0.28s\n",
            "Epoch [6/50], Loss: 0.3714, Time: 0.28s\n",
            "Epoch [7/50], Loss: 0.3539, Time: 0.29s\n",
            "Epoch [8/50], Loss: 0.3756, Time: 0.27s\n",
            "Epoch [9/50], Loss: 0.3606, Time: 0.28s\n",
            "Epoch [10/50], Loss: 0.3348, Time: 0.29s\n",
            "Epoch [11/50], Loss: 0.3603, Time: 0.27s\n",
            "Epoch [12/50], Loss: 0.3438, Time: 0.29s\n",
            "Epoch [13/50], Loss: 0.3611, Time: 0.29s\n",
            "Epoch [14/50], Loss: 0.3262, Time: 0.27s\n",
            "Epoch [15/50], Loss: 0.3536, Time: 0.29s\n",
            "Epoch [16/50], Loss: 0.3309, Time: 0.28s\n",
            "Epoch [17/50], Loss: 0.3282, Time: 0.28s\n",
            "Epoch [18/50], Loss: 0.3405, Time: 0.29s\n",
            "Epoch [19/50], Loss: 0.3075, Time: 0.27s\n",
            "Epoch [20/50], Loss: 0.3177, Time: 0.28s\n",
            "Epoch [21/50], Loss: 0.3030, Time: 0.29s\n",
            "Epoch [22/50], Loss: 0.3174, Time: 0.29s\n",
            "Epoch [23/50], Loss: 0.3055, Time: 0.30s\n",
            "Epoch [24/50], Loss: 0.2948, Time: 0.29s\n",
            "Epoch [25/50], Loss: 0.2837, Time: 0.30s\n",
            "Epoch [26/50], Loss: 0.2786, Time: 0.29s\n",
            "Epoch [27/50], Loss: 0.2921, Time: 0.28s\n",
            "Epoch [28/50], Loss: 0.2684, Time: 0.27s\n",
            "Epoch [29/50], Loss: 0.2830, Time: 0.30s\n",
            "Epoch [30/50], Loss: 0.2782, Time: 0.28s\n",
            "Epoch [31/50], Loss: 0.2817, Time: 0.28s\n",
            "Epoch [32/50], Loss: 0.2556, Time: 0.28s\n",
            "Epoch [33/50], Loss: 0.3066, Time: 0.27s\n",
            "Epoch [34/50], Loss: 0.2797, Time: 0.28s\n",
            "Epoch [35/50], Loss: 0.2702, Time: 0.27s\n",
            "Epoch [36/50], Loss: 0.2558, Time: 0.28s\n",
            "Epoch [37/50], Loss: 0.2414, Time: 0.27s\n",
            "Epoch [38/50], Loss: 0.2727, Time: 0.28s\n",
            "Epoch [39/50], Loss: 0.2579, Time: 0.28s\n",
            "Epoch [40/50], Loss: 0.2319, Time: 0.28s\n",
            "Epoch [41/50], Loss: 0.2528, Time: 0.27s\n",
            "Epoch [42/50], Loss: 0.2235, Time: 0.28s\n",
            "Epoch [43/50], Loss: 0.2634, Time: 0.27s\n",
            "Epoch [44/50], Loss: 0.2406, Time: 0.27s\n",
            "Epoch [45/50], Loss: 0.2304, Time: 0.28s\n",
            "Epoch [46/50], Loss: 0.2349, Time: 0.28s\n",
            "Epoch [47/50], Loss: 0.2267, Time: 0.27s\n",
            "Epoch [48/50], Loss: 0.2397, Time: 0.29s\n",
            "Epoch [49/50], Loss: 0.2281, Time: 0.29s\n",
            "Epoch [50/50], Loss: 0.2518, Time: 0.27s\n",
            "\n",
            "Training with Parameters: Hidden Layers=[32], Activation=relu, LR=0.01, Batch Size=32, Epochs=50, Dropout=0.2, L2=0.0001\n",
            "Epoch [1/50], Loss: 0.4770, Time: 0.27s\n",
            "Epoch [2/50], Loss: 0.3391, Time: 0.28s\n",
            "Epoch [3/50], Loss: 0.3200, Time: 0.28s\n",
            "Epoch [4/50], Loss: 0.3056, Time: 0.28s\n",
            "Epoch [5/50], Loss: 0.2930, Time: 0.29s\n",
            "Epoch [6/50], Loss: 0.3011, Time: 0.28s\n",
            "Epoch [7/50], Loss: 0.2862, Time: 0.28s\n",
            "Epoch [8/50], Loss: 0.2666, Time: 0.27s\n",
            "Epoch [9/50], Loss: 0.2609, Time: 0.29s\n",
            "Epoch [10/50], Loss: 0.2353, Time: 0.29s\n",
            "Epoch [11/50], Loss: 0.2420, Time: 0.28s\n",
            "Epoch [12/50], Loss: 0.2725, Time: 0.30s\n",
            "Epoch [13/50], Loss: 0.2382, Time: 0.31s\n",
            "Epoch [14/50], Loss: 0.2417, Time: 0.29s\n",
            "Epoch [15/50], Loss: 0.2194, Time: 0.29s\n",
            "Epoch [16/50], Loss: 0.2652, Time: 0.30s\n",
            "Epoch [17/50], Loss: 0.2221, Time: 0.30s\n",
            "Epoch [18/50], Loss: 0.2260, Time: 0.27s\n",
            "Epoch [19/50], Loss: 0.1908, Time: 0.27s\n",
            "Epoch [20/50], Loss: 0.2085, Time: 0.29s\n",
            "Epoch [21/50], Loss: 0.1990, Time: 0.29s\n",
            "Epoch [22/50], Loss: 0.2483, Time: 0.28s\n",
            "Epoch [23/50], Loss: 0.1918, Time: 0.27s\n",
            "Epoch [24/50], Loss: 0.2139, Time: 0.29s\n",
            "Epoch [25/50], Loss: 0.2019, Time: 0.29s\n",
            "Epoch [26/50], Loss: 0.1815, Time: 0.28s\n",
            "Epoch [27/50], Loss: 0.2185, Time: 0.28s\n",
            "Epoch [28/50], Loss: 0.2285, Time: 0.28s\n",
            "Epoch [29/50], Loss: 0.2102, Time: 0.28s\n",
            "Epoch [30/50], Loss: 0.2153, Time: 0.27s\n",
            "Epoch [31/50], Loss: 0.2028, Time: 0.29s\n",
            "Epoch [32/50], Loss: 0.1755, Time: 0.28s\n",
            "Epoch [33/50], Loss: 0.1938, Time: 0.28s\n",
            "Epoch [34/50], Loss: 0.2282, Time: 0.27s\n",
            "Epoch [35/50], Loss: 0.1899, Time: 0.29s\n",
            "Epoch [36/50], Loss: 0.2121, Time: 0.29s\n",
            "Epoch [37/50], Loss: 0.1734, Time: 0.29s\n",
            "Epoch [38/50], Loss: 0.1769, Time: 0.29s\n",
            "Epoch [39/50], Loss: 0.1753, Time: 0.30s\n",
            "Epoch [40/50], Loss: 0.1837, Time: 0.30s\n",
            "Epoch [41/50], Loss: 0.1811, Time: 0.34s\n",
            "Epoch [42/50], Loss: 0.2022, Time: 0.31s\n",
            "Epoch [43/50], Loss: 0.1835, Time: 0.28s\n",
            "Epoch [44/50], Loss: 0.1803, Time: 0.27s\n",
            "Epoch [45/50], Loss: 0.1819, Time: 0.28s\n",
            "Epoch [46/50], Loss: 0.1852, Time: 0.28s\n",
            "Epoch [47/50], Loss: 0.1705, Time: 0.28s\n",
            "Epoch [48/50], Loss: 0.2033, Time: 0.28s\n",
            "Epoch [49/50], Loss: 0.1843, Time: 0.28s\n",
            "Epoch [50/50], Loss: 0.2220, Time: 0.28s\n",
            "\n",
            "Training with Parameters: Hidden Layers=[32], Activation=softmax, LR=0.01, Batch Size=32, Epochs=50, Dropout=0.2, L2=0.0001\n",
            "Epoch [1/50], Loss: 0.6441, Time: 0.28s\n",
            "Epoch [2/50], Loss: 0.5442, Time: 0.30s\n",
            "Epoch [3/50], Loss: 0.4548, Time: 0.30s\n",
            "Epoch [4/50], Loss: 0.3961, Time: 0.29s\n",
            "Epoch [5/50], Loss: 0.3512, Time: 0.30s\n",
            "Epoch [6/50], Loss: 0.3332, Time: 0.31s\n",
            "Epoch [7/50], Loss: 0.3190, Time: 0.31s\n",
            "Epoch [8/50], Loss: 0.3073, Time: 0.29s\n",
            "Epoch [9/50], Loss: 0.2774, Time: 0.28s\n",
            "Epoch [10/50], Loss: 0.2531, Time: 0.28s\n",
            "Epoch [11/50], Loss: 0.2754, Time: 0.29s\n",
            "Epoch [12/50], Loss: 0.2597, Time: 0.29s\n",
            "Epoch [13/50], Loss: 0.2583, Time: 0.28s\n",
            "Epoch [14/50], Loss: 0.2703, Time: 0.28s\n",
            "Epoch [15/50], Loss: 0.2368, Time: 0.29s\n",
            "Epoch [16/50], Loss: 0.2433, Time: 0.28s\n",
            "Epoch [17/50], Loss: 0.2616, Time: 0.28s\n",
            "Epoch [18/50], Loss: 0.2537, Time: 0.28s\n",
            "Epoch [19/50], Loss: 0.2317, Time: 0.28s\n",
            "Epoch [20/50], Loss: 0.2568, Time: 0.29s\n",
            "Epoch [21/50], Loss: 0.2201, Time: 0.28s\n",
            "Epoch [22/50], Loss: 0.2171, Time: 0.28s\n",
            "Epoch [23/50], Loss: 0.2014, Time: 0.29s\n",
            "Epoch [24/50], Loss: 0.2082, Time: 0.29s\n",
            "Epoch [25/50], Loss: 0.2122, Time: 0.29s\n",
            "Epoch [26/50], Loss: 0.2103, Time: 0.27s\n",
            "Epoch [27/50], Loss: 0.2058, Time: 0.28s\n",
            "Epoch [28/50], Loss: 0.2292, Time: 0.28s\n",
            "Epoch [29/50], Loss: 0.2296, Time: 0.29s\n",
            "Epoch [30/50], Loss: 0.2261, Time: 0.29s\n",
            "Epoch [31/50], Loss: 0.2227, Time: 0.31s\n",
            "Epoch [32/50], Loss: 0.2189, Time: 0.29s\n",
            "Epoch [33/50], Loss: 0.1873, Time: 0.31s\n",
            "Epoch [34/50], Loss: 0.1974, Time: 0.28s\n",
            "Epoch [35/50], Loss: 0.1950, Time: 0.28s\n",
            "Epoch [36/50], Loss: 0.1881, Time: 0.28s\n",
            "Epoch [37/50], Loss: 0.2098, Time: 0.28s\n",
            "Epoch [38/50], Loss: 0.1772, Time: 0.28s\n",
            "Epoch [39/50], Loss: 0.1844, Time: 0.29s\n",
            "Epoch [40/50], Loss: 0.1858, Time: 0.29s\n",
            "Epoch [41/50], Loss: 0.1892, Time: 0.31s\n",
            "Epoch [42/50], Loss: 0.1884, Time: 0.30s\n",
            "Epoch [43/50], Loss: 0.1890, Time: 0.31s\n",
            "Epoch [44/50], Loss: 0.1618, Time: 0.32s\n",
            "Epoch [45/50], Loss: 0.1837, Time: 0.30s\n",
            "Epoch [46/50], Loss: 0.1827, Time: 0.30s\n",
            "Epoch [47/50], Loss: 0.1906, Time: 0.32s\n",
            "Epoch [48/50], Loss: 0.1828, Time: 0.31s\n",
            "Epoch [49/50], Loss: 0.2118, Time: 0.29s\n",
            "Epoch [50/50], Loss: 0.1737, Time: 0.29s\n",
            "\n",
            "Training with Parameters: Hidden Layers=[32], Activation=tanh, LR=0.01, Batch Size=32, Epochs=50, Dropout=0.2, L2=0.0001\n",
            "Epoch [1/50], Loss: 0.4436, Time: 0.29s\n",
            "Epoch [2/50], Loss: 0.3294, Time: 0.29s\n",
            "Epoch [3/50], Loss: 0.3460, Time: 0.28s\n",
            "Epoch [4/50], Loss: 0.3269, Time: 0.29s\n",
            "Epoch [5/50], Loss: 0.2988, Time: 0.29s\n",
            "Epoch [6/50], Loss: 0.3043, Time: 0.29s\n",
            "Epoch [7/50], Loss: 0.2844, Time: 0.29s\n",
            "Epoch [8/50], Loss: 0.2726, Time: 0.28s\n",
            "Epoch [9/50], Loss: 0.2726, Time: 0.27s\n",
            "Epoch [10/50], Loss: 0.2424, Time: 0.28s\n",
            "Epoch [11/50], Loss: 0.2592, Time: 0.30s\n",
            "Epoch [12/50], Loss: 0.2534, Time: 0.27s\n",
            "Epoch [13/50], Loss: 0.2420, Time: 0.29s\n",
            "Epoch [14/50], Loss: 0.2285, Time: 0.29s\n",
            "Epoch [15/50], Loss: 0.2443, Time: 0.29s\n",
            "Epoch [16/50], Loss: 0.2293, Time: 0.29s\n",
            "Epoch [17/50], Loss: 0.2165, Time: 0.28s\n",
            "Epoch [18/50], Loss: 0.2103, Time: 0.28s\n",
            "Epoch [19/50], Loss: 0.2090, Time: 0.29s\n",
            "Epoch [20/50], Loss: 0.2047, Time: 0.29s\n",
            "Epoch [21/50], Loss: 0.1873, Time: 0.29s\n",
            "Epoch [22/50], Loss: 0.1900, Time: 0.28s\n",
            "Epoch [23/50], Loss: 0.2252, Time: 0.29s\n",
            "Epoch [24/50], Loss: 0.2062, Time: 0.29s\n",
            "Epoch [25/50], Loss: 0.2080, Time: 0.28s\n",
            "Epoch [26/50], Loss: 0.1566, Time: 0.30s\n",
            "Epoch [27/50], Loss: 0.1830, Time: 0.29s\n",
            "Epoch [28/50], Loss: 0.1996, Time: 0.29s\n",
            "Epoch [29/50], Loss: 0.1897, Time: 0.30s\n",
            "Epoch [30/50], Loss: 0.1521, Time: 0.29s\n",
            "Epoch [31/50], Loss: 0.1749, Time: 0.29s\n",
            "Epoch [32/50], Loss: 0.1616, Time: 0.29s\n",
            "Epoch [33/50], Loss: 0.1646, Time: 0.30s\n",
            "Epoch [34/50], Loss: 0.1615, Time: 0.31s\n",
            "Epoch [35/50], Loss: 0.1495, Time: 0.29s\n",
            "Epoch [36/50], Loss: 0.1520, Time: 0.31s\n",
            "Epoch [37/50], Loss: 0.1995, Time: 0.31s\n",
            "Epoch [38/50], Loss: 0.1529, Time: 0.30s\n",
            "Epoch [39/50], Loss: 0.1880, Time: 0.29s\n",
            "Epoch [40/50], Loss: 0.1716, Time: 0.29s\n",
            "Epoch [41/50], Loss: 0.1787, Time: 0.29s\n",
            "Epoch [42/50], Loss: 0.1555, Time: 0.28s\n",
            "Epoch [43/50], Loss: 0.1703, Time: 0.31s\n",
            "Epoch [44/50], Loss: 0.1428, Time: 0.28s\n",
            "Epoch [45/50], Loss: 0.1827, Time: 0.29s\n",
            "Epoch [46/50], Loss: 0.1361, Time: 0.29s\n",
            "Epoch [47/50], Loss: 0.1473, Time: 0.29s\n",
            "Epoch [48/50], Loss: 0.1485, Time: 0.29s\n",
            "Epoch [49/50], Loss: 0.1511, Time: 0.29s\n",
            "Epoch [50/50], Loss: 0.1574, Time: 0.28s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bandingkan berbagai fungsi aktivasi.\n"
      ],
      "metadata": {
        "id": "nSMsobz_o7Iu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Eksperimen 3: Epochs**\n"
      ],
      "metadata": {
        "id": "DlJwscBto9Hc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 3: Comparing Epochs\n",
        "epochs_options = [1, 10, 25, 50, 100, 250]\n",
        "results_epochs = []\n",
        "for epochs in epochs_options:\n",
        "    accuracy = train_and_evaluate(hidden_layers=[32], activation_fn='relu', learning_rate=0.01, batch_size=32, epochs=epochs, dropout_rate=0.2, weight_decay=1e-4)\n",
        "    results_epochs.append({'epochs': epochs, 'accuracy': accuracy})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rxNVdHdo8lu",
        "outputId": "a7cab9c8-08e4-4c62-caf4-03564ca667b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training with Parameters: Hidden Layers=[32], Activation=relu, LR=0.01, Batch Size=32, Epochs=1, Dropout=0.2, L2=0.0001\n",
            "Epoch [1/1], Loss: 0.4613, Time: 0.31s\n",
            "\n",
            "Training with Parameters: Hidden Layers=[32], Activation=relu, LR=0.01, Batch Size=32, Epochs=10, Dropout=0.2, L2=0.0001\n",
            "Epoch [1/10], Loss: 0.4383, Time: 0.33s\n",
            "Epoch [2/10], Loss: 0.3378, Time: 0.29s\n",
            "Epoch [3/10], Loss: 0.3148, Time: 0.29s\n",
            "Epoch [4/10], Loss: 0.2849, Time: 0.31s\n",
            "Epoch [5/10], Loss: 0.2669, Time: 0.29s\n",
            "Epoch [6/10], Loss: 0.2815, Time: 0.29s\n",
            "Epoch [7/10], Loss: 0.2670, Time: 0.30s\n",
            "Epoch [8/10], Loss: 0.2832, Time: 0.30s\n",
            "Epoch [9/10], Loss: 0.2750, Time: 0.29s\n",
            "Epoch [10/10], Loss: 0.2394, Time: 0.29s\n",
            "\n",
            "Training with Parameters: Hidden Layers=[32], Activation=relu, LR=0.01, Batch Size=32, Epochs=25, Dropout=0.2, L2=0.0001\n",
            "Epoch [1/25], Loss: 0.4080, Time: 0.30s\n",
            "Epoch [2/25], Loss: 0.3285, Time: 0.30s\n",
            "Epoch [3/25], Loss: 0.3065, Time: 0.30s\n",
            "Epoch [4/25], Loss: 0.3202, Time: 0.30s\n",
            "Epoch [5/25], Loss: 0.3040, Time: 0.30s\n",
            "Epoch [6/25], Loss: 0.2969, Time: 0.29s\n",
            "Epoch [7/25], Loss: 0.2546, Time: 0.28s\n",
            "Epoch [8/25], Loss: 0.2750, Time: 0.30s\n",
            "Epoch [9/25], Loss: 0.2436, Time: 0.30s\n",
            "Epoch [10/25], Loss: 0.2400, Time: 0.30s\n",
            "Epoch [11/25], Loss: 0.2448, Time: 0.31s\n",
            "Epoch [12/25], Loss: 0.2631, Time: 0.31s\n",
            "Epoch [13/25], Loss: 0.2397, Time: 0.32s\n",
            "Epoch [14/25], Loss: 0.2334, Time: 0.31s\n",
            "Epoch [15/25], Loss: 0.2788, Time: 0.31s\n",
            "Epoch [16/25], Loss: 0.2529, Time: 0.28s\n",
            "Epoch [17/25], Loss: 0.2145, Time: 0.29s\n",
            "Epoch [18/25], Loss: 0.2481, Time: 0.30s\n",
            "Epoch [19/25], Loss: 0.2018, Time: 0.29s\n",
            "Epoch [20/25], Loss: 0.2075, Time: 0.30s\n",
            "Epoch [21/25], Loss: 0.2153, Time: 0.30s\n",
            "Epoch [22/25], Loss: 0.1981, Time: 0.29s\n",
            "Epoch [23/25], Loss: 0.2135, Time: 0.28s\n",
            "Epoch [24/25], Loss: 0.1962, Time: 0.29s\n",
            "Epoch [25/25], Loss: 0.1992, Time: 0.29s\n",
            "\n",
            "Training with Parameters: Hidden Layers=[32], Activation=relu, LR=0.01, Batch Size=32, Epochs=50, Dropout=0.2, L2=0.0001\n",
            "Epoch [1/50], Loss: 0.4540, Time: 0.29s\n",
            "Epoch [2/50], Loss: 0.3396, Time: 0.30s\n",
            "Epoch [3/50], Loss: 0.3345, Time: 0.30s\n",
            "Epoch [4/50], Loss: 0.3172, Time: 0.29s\n",
            "Epoch [5/50], Loss: 0.3095, Time: 0.29s\n",
            "Epoch [6/50], Loss: 0.2710, Time: 0.31s\n",
            "Epoch [7/50], Loss: 0.2762, Time: 0.29s\n",
            "Epoch [8/50], Loss: 0.2566, Time: 0.30s\n",
            "Epoch [9/50], Loss: 0.2671, Time: 0.31s\n",
            "Epoch [10/50], Loss: 0.2413, Time: 0.30s\n",
            "Epoch [11/50], Loss: 0.2291, Time: 0.31s\n",
            "Epoch [12/50], Loss: 0.2443, Time: 0.29s\n",
            "Epoch [13/50], Loss: 0.2167, Time: 0.29s\n",
            "Epoch [14/50], Loss: 0.2253, Time: 0.29s\n",
            "Epoch [15/50], Loss: 0.2478, Time: 0.30s\n",
            "Epoch [16/50], Loss: 0.2309, Time: 0.29s\n",
            "Epoch [17/50], Loss: 0.2030, Time: 0.29s\n",
            "Epoch [18/50], Loss: 0.2493, Time: 0.29s\n",
            "Epoch [19/50], Loss: 0.1823, Time: 0.30s\n",
            "Epoch [20/50], Loss: 0.2241, Time: 0.30s\n",
            "Epoch [21/50], Loss: 0.1955, Time: 0.30s\n",
            "Epoch [22/50], Loss: 0.2064, Time: 0.29s\n",
            "Epoch [23/50], Loss: 0.2044, Time: 0.30s\n",
            "Epoch [24/50], Loss: 0.1956, Time: 0.32s\n",
            "Epoch [25/50], Loss: 0.2099, Time: 0.31s\n",
            "Epoch [26/50], Loss: 0.2254, Time: 0.32s\n",
            "Epoch [27/50], Loss: 0.1909, Time: 0.32s\n",
            "Epoch [28/50], Loss: 0.1943, Time: 0.32s\n",
            "Epoch [29/50], Loss: 0.2111, Time: 0.30s\n",
            "Epoch [30/50], Loss: 0.2031, Time: 0.30s\n",
            "Epoch [31/50], Loss: 0.1763, Time: 0.28s\n",
            "Epoch [32/50], Loss: 0.1976, Time: 0.55s\n",
            "Epoch [33/50], Loss: 0.1849, Time: 0.29s\n",
            "Epoch [34/50], Loss: 0.1757, Time: 0.29s\n",
            "Epoch [35/50], Loss: 0.1764, Time: 0.29s\n",
            "Epoch [36/50], Loss: 0.2119, Time: 0.30s\n",
            "Epoch [37/50], Loss: 0.1568, Time: 0.30s\n",
            "Epoch [38/50], Loss: 0.2059, Time: 0.29s\n",
            "Epoch [39/50], Loss: 0.1767, Time: 0.30s\n",
            "Epoch [40/50], Loss: 0.1799, Time: 0.30s\n",
            "Epoch [41/50], Loss: 0.1882, Time: 0.30s\n",
            "Epoch [42/50], Loss: 0.1797, Time: 0.31s\n",
            "Epoch [43/50], Loss: 0.1592, Time: 0.30s\n",
            "Epoch [44/50], Loss: 0.1915, Time: 0.31s\n",
            "Epoch [45/50], Loss: 0.1845, Time: 0.30s\n",
            "Epoch [46/50], Loss: 0.1828, Time: 0.30s\n",
            "Epoch [47/50], Loss: 0.1871, Time: 0.31s\n",
            "Epoch [48/50], Loss: 0.1496, Time: 0.30s\n",
            "Epoch [49/50], Loss: 0.1795, Time: 0.30s\n",
            "Epoch [50/50], Loss: 0.1661, Time: 0.29s\n",
            "\n",
            "Training with Parameters: Hidden Layers=[32], Activation=relu, LR=0.01, Batch Size=32, Epochs=100, Dropout=0.2, L2=0.0001\n",
            "Epoch [1/100], Loss: 0.4635, Time: 0.31s\n",
            "Epoch [2/100], Loss: 0.3251, Time: 0.30s\n",
            "Epoch [3/100], Loss: 0.3157, Time: 0.30s\n",
            "Epoch [4/100], Loss: 0.3038, Time: 0.32s\n",
            "Epoch [5/100], Loss: 0.2788, Time: 0.30s\n",
            "Epoch [6/100], Loss: 0.2727, Time: 0.30s\n",
            "Epoch [7/100], Loss: 0.2664, Time: 0.33s\n",
            "Epoch [8/100], Loss: 0.2755, Time: 0.30s\n",
            "Epoch [9/100], Loss: 0.2451, Time: 0.29s\n",
            "Epoch [10/100], Loss: 0.2516, Time: 0.30s\n",
            "Epoch [11/100], Loss: 0.2858, Time: 0.31s\n",
            "Epoch [12/100], Loss: 0.2566, Time: 0.32s\n",
            "Epoch [13/100], Loss: 0.2553, Time: 0.31s\n",
            "Epoch [14/100], Loss: 0.2431, Time: 0.32s\n",
            "Epoch [15/100], Loss: 0.2275, Time: 0.32s\n",
            "Epoch [16/100], Loss: 0.2282, Time: 0.30s\n",
            "Epoch [17/100], Loss: 0.2329, Time: 0.30s\n",
            "Epoch [18/100], Loss: 0.2375, Time: 0.30s\n",
            "Epoch [19/100], Loss: 0.2196, Time: 0.30s\n",
            "Epoch [20/100], Loss: 0.2392, Time: 0.30s\n",
            "Epoch [21/100], Loss: 0.2335, Time: 0.30s\n",
            "Epoch [22/100], Loss: 0.1846, Time: 0.29s\n",
            "Epoch [23/100], Loss: 0.1994, Time: 0.30s\n",
            "Epoch [24/100], Loss: 0.2162, Time: 0.30s\n",
            "Epoch [25/100], Loss: 0.2081, Time: 0.29s\n",
            "Epoch [26/100], Loss: 0.2354, Time: 0.30s\n",
            "Epoch [27/100], Loss: 0.2064, Time: 0.30s\n",
            "Epoch [28/100], Loss: 0.2059, Time: 0.30s\n",
            "Epoch [29/100], Loss: 0.1909, Time: 0.29s\n",
            "Epoch [30/100], Loss: 0.1915, Time: 0.29s\n",
            "Epoch [31/100], Loss: 0.2072, Time: 0.30s\n",
            "Epoch [32/100], Loss: 0.1855, Time: 0.30s\n",
            "Epoch [33/100], Loss: 0.2182, Time: 0.30s\n",
            "Epoch [34/100], Loss: 0.1876, Time: 0.30s\n",
            "Epoch [35/100], Loss: 0.1765, Time: 0.29s\n",
            "Epoch [36/100], Loss: 0.1523, Time: 0.31s\n",
            "Epoch [37/100], Loss: 0.2004, Time: 0.30s\n",
            "Epoch [38/100], Loss: 0.2120, Time: 0.30s\n",
            "Epoch [39/100], Loss: 0.2002, Time: 0.30s\n",
            "Epoch [40/100], Loss: 0.2069, Time: 0.31s\n",
            "Epoch [41/100], Loss: 0.2070, Time: 0.30s\n",
            "Epoch [42/100], Loss: 0.1589, Time: 0.30s\n",
            "Epoch [43/100], Loss: 0.1918, Time: 0.30s\n",
            "Epoch [44/100], Loss: 0.1626, Time: 0.30s\n",
            "Epoch [45/100], Loss: 0.2133, Time: 0.30s\n",
            "Epoch [46/100], Loss: 0.1863, Time: 0.30s\n",
            "Epoch [47/100], Loss: 0.1754, Time: 0.29s\n",
            "Epoch [48/100], Loss: 0.1680, Time: 0.30s\n",
            "Epoch [49/100], Loss: 0.1740, Time: 0.30s\n",
            "Epoch [50/100], Loss: 0.1998, Time: 0.31s\n",
            "Epoch [51/100], Loss: 0.1943, Time: 0.31s\n",
            "Epoch [52/100], Loss: 0.1633, Time: 0.31s\n",
            "Epoch [53/100], Loss: 0.1582, Time: 0.32s\n",
            "Epoch [54/100], Loss: 0.1798, Time: 0.32s\n",
            "Epoch [55/100], Loss: 0.1769, Time: 0.30s\n",
            "Epoch [56/100], Loss: 0.2092, Time: 0.31s\n",
            "Epoch [57/100], Loss: 0.1871, Time: 0.30s\n",
            "Epoch [58/100], Loss: 0.1781, Time: 0.30s\n",
            "Epoch [59/100], Loss: 0.1488, Time: 0.31s\n",
            "Epoch [60/100], Loss: 0.1783, Time: 0.30s\n",
            "Epoch [61/100], Loss: 0.1801, Time: 0.30s\n",
            "Epoch [62/100], Loss: 0.1803, Time: 0.30s\n",
            "Epoch [63/100], Loss: 0.1290, Time: 0.30s\n",
            "Epoch [64/100], Loss: 0.1657, Time: 0.30s\n",
            "Epoch [65/100], Loss: 0.1718, Time: 0.30s\n",
            "Epoch [66/100], Loss: 0.2056, Time: 0.31s\n",
            "Epoch [67/100], Loss: 0.1837, Time: 0.30s\n",
            "Epoch [68/100], Loss: 0.1626, Time: 0.30s\n",
            "Epoch [69/100], Loss: 0.1856, Time: 0.29s\n",
            "Epoch [70/100], Loss: 0.1539, Time: 0.31s\n",
            "Epoch [71/100], Loss: 0.1722, Time: 0.30s\n",
            "Epoch [72/100], Loss: 0.1844, Time: 0.30s\n",
            "Epoch [73/100], Loss: 0.1712, Time: 0.31s\n",
            "Epoch [74/100], Loss: 0.1713, Time: 0.30s\n",
            "Epoch [75/100], Loss: 0.1593, Time: 0.30s\n",
            "Epoch [76/100], Loss: 0.1893, Time: 0.30s\n",
            "Epoch [77/100], Loss: 0.1520, Time: 0.31s\n",
            "Epoch [78/100], Loss: 0.1546, Time: 0.30s\n",
            "Epoch [79/100], Loss: 0.1498, Time: 0.30s\n",
            "Epoch [80/100], Loss: 0.1406, Time: 0.31s\n",
            "Epoch [81/100], Loss: 0.1635, Time: 0.31s\n",
            "Epoch [82/100], Loss: 0.1404, Time: 0.29s\n",
            "Epoch [83/100], Loss: 0.1543, Time: 0.30s\n",
            "Epoch [84/100], Loss: 0.1300, Time: 0.30s\n",
            "Epoch [85/100], Loss: 0.1259, Time: 0.30s\n",
            "Epoch [86/100], Loss: 0.1520, Time: 0.31s\n",
            "Epoch [87/100], Loss: 0.1464, Time: 0.31s\n",
            "Epoch [88/100], Loss: 0.1873, Time: 0.33s\n",
            "Epoch [89/100], Loss: 0.1486, Time: 0.32s\n",
            "Epoch [90/100], Loss: 0.1414, Time: 0.32s\n",
            "Epoch [91/100], Loss: 0.1604, Time: 0.31s\n",
            "Epoch [92/100], Loss: 0.1407, Time: 0.35s\n",
            "Epoch [93/100], Loss: 0.1305, Time: 0.33s\n",
            "Epoch [94/100], Loss: 0.1558, Time: 0.30s\n",
            "Epoch [95/100], Loss: 0.1618, Time: 0.31s\n",
            "Epoch [96/100], Loss: 0.1597, Time: 0.33s\n",
            "Epoch [97/100], Loss: 0.1528, Time: 0.31s\n",
            "Epoch [98/100], Loss: 0.1800, Time: 0.32s\n",
            "Epoch [99/100], Loss: 0.1509, Time: 0.31s\n",
            "Epoch [100/100], Loss: 0.1322, Time: 0.31s\n",
            "\n",
            "Training with Parameters: Hidden Layers=[32], Activation=relu, LR=0.01, Batch Size=32, Epochs=250, Dropout=0.2, L2=0.0001\n",
            "Epoch [1/250], Loss: 0.4751, Time: 0.30s\n",
            "Epoch [2/250], Loss: 0.3298, Time: 0.31s\n",
            "Epoch [3/250], Loss: 0.3202, Time: 0.30s\n",
            "Epoch [4/250], Loss: 0.3004, Time: 0.30s\n",
            "Epoch [5/250], Loss: 0.2814, Time: 0.31s\n",
            "Epoch [6/250], Loss: 0.2835, Time: 0.30s\n",
            "Epoch [7/250], Loss: 0.3025, Time: 0.31s\n",
            "Epoch [8/250], Loss: 0.2528, Time: 0.30s\n",
            "Epoch [9/250], Loss: 0.2578, Time: 0.31s\n",
            "Epoch [10/250], Loss: 0.2510, Time: 0.30s\n",
            "Epoch [11/250], Loss: 0.2846, Time: 0.30s\n",
            "Epoch [12/250], Loss: 0.2511, Time: 0.31s\n",
            "Epoch [13/250], Loss: 0.2430, Time: 0.31s\n",
            "Epoch [14/250], Loss: 0.2452, Time: 0.30s\n",
            "Epoch [15/250], Loss: 0.2309, Time: 0.30s\n",
            "Epoch [16/250], Loss: 0.2332, Time: 0.30s\n",
            "Epoch [17/250], Loss: 0.2498, Time: 0.30s\n",
            "Epoch [18/250], Loss: 0.2466, Time: 0.30s\n",
            "Epoch [19/250], Loss: 0.2173, Time: 0.30s\n",
            "Epoch [20/250], Loss: 0.2415, Time: 0.31s\n",
            "Epoch [21/250], Loss: 0.2350, Time: 0.30s\n",
            "Epoch [22/250], Loss: 0.2077, Time: 0.31s\n",
            "Epoch [23/250], Loss: 0.2039, Time: 0.31s\n",
            "Epoch [24/250], Loss: 0.1889, Time: 0.30s\n",
            "Epoch [25/250], Loss: 0.2030, Time: 0.33s\n",
            "Epoch [26/250], Loss: 0.2184, Time: 0.32s\n",
            "Epoch [27/250], Loss: 0.2135, Time: 0.33s\n",
            "Epoch [28/250], Loss: 0.2107, Time: 0.32s\n",
            "Epoch [29/250], Loss: 0.1982, Time: 0.32s\n",
            "Epoch [30/250], Loss: 0.2010, Time: 0.34s\n",
            "Epoch [31/250], Loss: 0.1961, Time: 0.32s\n",
            "Epoch [32/250], Loss: 0.1947, Time: 0.30s\n",
            "Epoch [33/250], Loss: 0.2101, Time: 0.31s\n",
            "Epoch [34/250], Loss: 0.1849, Time: 0.31s\n",
            "Epoch [35/250], Loss: 0.1919, Time: 0.30s\n",
            "Epoch [36/250], Loss: 0.1827, Time: 0.31s\n",
            "Epoch [37/250], Loss: 0.1867, Time: 0.31s\n",
            "Epoch [38/250], Loss: 0.1780, Time: 0.30s\n",
            "Epoch [39/250], Loss: 0.1779, Time: 0.31s\n",
            "Epoch [40/250], Loss: 0.1841, Time: 0.30s\n",
            "Epoch [41/250], Loss: 0.1885, Time: 0.31s\n",
            "Epoch [42/250], Loss: 0.1640, Time: 0.31s\n",
            "Epoch [43/250], Loss: 0.1945, Time: 0.31s\n",
            "Epoch [44/250], Loss: 0.1892, Time: 0.30s\n",
            "Epoch [45/250], Loss: 0.1868, Time: 0.31s\n",
            "Epoch [46/250], Loss: 0.1877, Time: 0.31s\n",
            "Epoch [47/250], Loss: 0.1668, Time: 0.31s\n",
            "Epoch [48/250], Loss: 0.1926, Time: 0.32s\n",
            "Epoch [49/250], Loss: 0.1659, Time: 0.32s\n",
            "Epoch [50/250], Loss: 0.1742, Time: 0.31s\n",
            "Epoch [51/250], Loss: 0.1851, Time: 0.30s\n",
            "Epoch [52/250], Loss: 0.1717, Time: 0.32s\n",
            "Epoch [53/250], Loss: 0.1572, Time: 0.30s\n",
            "Epoch [54/250], Loss: 0.1556, Time: 0.32s\n",
            "Epoch [55/250], Loss: 0.1832, Time: 0.32s\n",
            "Epoch [56/250], Loss: 0.1683, Time: 0.30s\n",
            "Epoch [57/250], Loss: 0.1553, Time: 0.31s\n",
            "Epoch [58/250], Loss: 0.1602, Time: 0.30s\n",
            "Epoch [59/250], Loss: 0.1837, Time: 0.31s\n",
            "Epoch [60/250], Loss: 0.1731, Time: 0.29s\n",
            "Epoch [61/250], Loss: 0.1522, Time: 0.30s\n",
            "Epoch [62/250], Loss: 0.1489, Time: 0.31s\n",
            "Epoch [63/250], Loss: 0.1723, Time: 0.33s\n",
            "Epoch [64/250], Loss: 0.1564, Time: 0.32s\n",
            "Epoch [65/250], Loss: 0.1577, Time: 0.32s\n",
            "Epoch [66/250], Loss: 0.1505, Time: 0.32s\n",
            "Epoch [67/250], Loss: 0.1438, Time: 0.33s\n",
            "Epoch [68/250], Loss: 0.1695, Time: 0.34s\n",
            "Epoch [69/250], Loss: 0.1395, Time: 0.32s\n",
            "Epoch [70/250], Loss: 0.1826, Time: 0.31s\n",
            "Epoch [71/250], Loss: 0.1382, Time: 0.31s\n",
            "Epoch [72/250], Loss: 0.1424, Time: 0.31s\n",
            "Epoch [73/250], Loss: 0.1433, Time: 0.30s\n",
            "Epoch [74/250], Loss: 0.1731, Time: 0.31s\n",
            "Epoch [75/250], Loss: 0.1363, Time: 0.31s\n",
            "Epoch [76/250], Loss: 0.1341, Time: 0.31s\n",
            "Epoch [77/250], Loss: 0.1563, Time: 0.30s\n",
            "Epoch [78/250], Loss: 0.1514, Time: 0.30s\n",
            "Epoch [79/250], Loss: 0.1349, Time: 0.31s\n",
            "Epoch [80/250], Loss: 0.1390, Time: 0.31s\n",
            "Epoch [81/250], Loss: 0.1139, Time: 0.30s\n",
            "Epoch [82/250], Loss: 0.1437, Time: 0.32s\n",
            "Epoch [83/250], Loss: 0.1777, Time: 0.31s\n",
            "Epoch [84/250], Loss: 0.1399, Time: 0.30s\n",
            "Epoch [85/250], Loss: 0.1336, Time: 0.31s\n",
            "Epoch [86/250], Loss: 0.1779, Time: 0.31s\n",
            "Epoch [87/250], Loss: 0.1679, Time: 0.30s\n",
            "Epoch [88/250], Loss: 0.1694, Time: 0.31s\n",
            "Epoch [89/250], Loss: 0.1281, Time: 0.32s\n",
            "Epoch [90/250], Loss: 0.1241, Time: 0.30s\n",
            "Epoch [91/250], Loss: 0.1574, Time: 0.31s\n",
            "Epoch [92/250], Loss: 0.1298, Time: 0.32s\n",
            "Epoch [93/250], Loss: 0.1285, Time: 0.30s\n",
            "Epoch [94/250], Loss: 0.1447, Time: 0.30s\n",
            "Epoch [95/250], Loss: 0.1361, Time: 0.30s\n",
            "Epoch [96/250], Loss: 0.1278, Time: 0.30s\n",
            "Epoch [97/250], Loss: 0.1387, Time: 0.30s\n",
            "Epoch [98/250], Loss: 0.1844, Time: 0.32s\n",
            "Epoch [99/250], Loss: 0.1223, Time: 0.31s\n",
            "Epoch [100/250], Loss: 0.1580, Time: 0.30s\n",
            "Epoch [101/250], Loss: 0.1416, Time: 0.32s\n",
            "Epoch [102/250], Loss: 0.1296, Time: 0.32s\n",
            "Epoch [103/250], Loss: 0.1248, Time: 0.32s\n",
            "Epoch [104/250], Loss: 0.1364, Time: 0.33s\n",
            "Epoch [105/250], Loss: 0.1559, Time: 0.32s\n",
            "Epoch [106/250], Loss: 0.1175, Time: 0.36s\n",
            "Epoch [107/250], Loss: 0.1109, Time: 0.32s\n",
            "Epoch [108/250], Loss: 0.1062, Time: 0.31s\n",
            "Epoch [109/250], Loss: 0.1363, Time: 0.31s\n",
            "Epoch [110/250], Loss: 0.1519, Time: 0.31s\n",
            "Epoch [111/250], Loss: 0.1276, Time: 0.32s\n",
            "Epoch [112/250], Loss: 0.1625, Time: 0.31s\n",
            "Epoch [113/250], Loss: 0.1538, Time: 0.31s\n",
            "Epoch [114/250], Loss: 0.1211, Time: 0.31s\n",
            "Epoch [115/250], Loss: 0.1683, Time: 0.31s\n",
            "Epoch [116/250], Loss: 0.1158, Time: 0.31s\n",
            "Epoch [117/250], Loss: 0.1105, Time: 0.31s\n",
            "Epoch [118/250], Loss: 0.1256, Time: 0.31s\n",
            "Epoch [119/250], Loss: 0.1221, Time: 0.31s\n",
            "Epoch [120/250], Loss: 0.1215, Time: 0.31s\n",
            "Epoch [121/250], Loss: 0.1287, Time: 0.32s\n",
            "Epoch [122/250], Loss: 0.1460, Time: 0.31s\n",
            "Epoch [123/250], Loss: 0.1431, Time: 0.33s\n",
            "Epoch [124/250], Loss: 0.1430, Time: 0.31s\n",
            "Epoch [125/250], Loss: 0.1460, Time: 0.30s\n",
            "Epoch [126/250], Loss: 0.1510, Time: 0.32s\n",
            "Epoch [127/250], Loss: 0.1529, Time: 0.31s\n",
            "Epoch [128/250], Loss: 0.1308, Time: 0.30s\n",
            "Epoch [129/250], Loss: 0.1408, Time: 0.32s\n",
            "Epoch [130/250], Loss: 0.1556, Time: 0.31s\n",
            "Epoch [131/250], Loss: 0.1377, Time: 0.31s\n",
            "Epoch [132/250], Loss: 0.1397, Time: 0.31s\n",
            "Epoch [133/250], Loss: 0.1485, Time: 0.30s\n",
            "Epoch [134/250], Loss: 0.1333, Time: 0.31s\n",
            "Epoch [135/250], Loss: 0.1430, Time: 0.30s\n",
            "Epoch [136/250], Loss: 0.1358, Time: 0.31s\n",
            "Epoch [137/250], Loss: 0.1232, Time: 0.31s\n",
            "Epoch [138/250], Loss: 0.1191, Time: 0.29s\n",
            "Epoch [139/250], Loss: 0.1835, Time: 0.33s\n",
            "Epoch [140/250], Loss: 0.1594, Time: 0.32s\n",
            "Epoch [141/250], Loss: 0.1159, Time: 0.31s\n",
            "Epoch [142/250], Loss: 0.1557, Time: 0.34s\n",
            "Epoch [143/250], Loss: 0.1584, Time: 0.35s\n",
            "Epoch [144/250], Loss: 0.1250, Time: 0.33s\n",
            "Epoch [145/250], Loss: 0.1034, Time: 0.32s\n",
            "Epoch [146/250], Loss: 0.1597, Time: 0.32s\n",
            "Epoch [147/250], Loss: 0.1357, Time: 0.31s\n",
            "Epoch [148/250], Loss: 0.1359, Time: 0.31s\n",
            "Epoch [149/250], Loss: 0.1262, Time: 0.31s\n",
            "Epoch [150/250], Loss: 0.1510, Time: 0.29s\n",
            "Epoch [151/250], Loss: 0.1377, Time: 0.32s\n",
            "Epoch [152/250], Loss: 0.1094, Time: 0.31s\n",
            "Epoch [153/250], Loss: 0.1301, Time: 0.32s\n",
            "Epoch [154/250], Loss: 0.1274, Time: 0.31s\n",
            "Epoch [155/250], Loss: 0.0849, Time: 0.31s\n",
            "Epoch [156/250], Loss: 0.1328, Time: 0.31s\n",
            "Epoch [157/250], Loss: 0.1163, Time: 0.30s\n",
            "Epoch [158/250], Loss: 0.1361, Time: 0.31s\n",
            "Epoch [159/250], Loss: 0.1304, Time: 0.31s\n",
            "Epoch [160/250], Loss: 0.1227, Time: 0.31s\n",
            "Epoch [161/250], Loss: 0.1571, Time: 0.31s\n",
            "Epoch [162/250], Loss: 0.1387, Time: 0.31s\n",
            "Epoch [163/250], Loss: 0.1248, Time: 0.31s\n",
            "Epoch [164/250], Loss: 0.1331, Time: 0.31s\n",
            "Epoch [165/250], Loss: 0.1254, Time: 0.29s\n",
            "Epoch [166/250], Loss: 0.1529, Time: 0.31s\n",
            "Epoch [167/250], Loss: 0.1368, Time: 0.30s\n",
            "Epoch [168/250], Loss: 0.1248, Time: 0.31s\n",
            "Epoch [169/250], Loss: 0.1221, Time: 0.31s\n",
            "Epoch [170/250], Loss: 0.1126, Time: 0.31s\n",
            "Epoch [171/250], Loss: 0.1067, Time: 0.30s\n",
            "Epoch [172/250], Loss: 0.1374, Time: 0.31s\n",
            "Epoch [173/250], Loss: 0.1516, Time: 0.31s\n",
            "Epoch [174/250], Loss: 0.1428, Time: 0.31s\n",
            "Epoch [175/250], Loss: 0.1189, Time: 0.33s\n",
            "Epoch [176/250], Loss: 0.1244, Time: 0.31s\n",
            "Epoch [177/250], Loss: 0.1142, Time: 0.33s\n",
            "Epoch [178/250], Loss: 0.1038, Time: 0.33s\n",
            "Epoch [179/250], Loss: 0.1173, Time: 0.33s\n",
            "Epoch [180/250], Loss: 0.1071, Time: 0.34s\n",
            "Epoch [181/250], Loss: 0.1238, Time: 0.32s\n",
            "Epoch [182/250], Loss: 0.1443, Time: 0.33s\n",
            "Epoch [183/250], Loss: 0.1393, Time: 0.32s\n",
            "Epoch [184/250], Loss: 0.1435, Time: 0.32s\n",
            "Epoch [185/250], Loss: 0.1646, Time: 0.32s\n",
            "Epoch [186/250], Loss: 0.0952, Time: 0.31s\n",
            "Epoch [187/250], Loss: 0.1387, Time: 0.30s\n",
            "Epoch [188/250], Loss: 0.1128, Time: 0.31s\n",
            "Epoch [189/250], Loss: 0.1383, Time: 0.30s\n",
            "Epoch [190/250], Loss: 0.1113, Time: 0.32s\n",
            "Epoch [191/250], Loss: 0.1253, Time: 0.31s\n",
            "Epoch [192/250], Loss: 0.1169, Time: 0.30s\n",
            "Epoch [193/250], Loss: 0.1170, Time: 0.31s\n",
            "Epoch [194/250], Loss: 0.1211, Time: 0.32s\n",
            "Epoch [195/250], Loss: 0.1351, Time: 0.31s\n",
            "Epoch [196/250], Loss: 0.1037, Time: 0.31s\n",
            "Epoch [197/250], Loss: 0.1238, Time: 0.30s\n",
            "Epoch [198/250], Loss: 0.1267, Time: 0.31s\n",
            "Epoch [199/250], Loss: 0.1403, Time: 0.32s\n",
            "Epoch [200/250], Loss: 0.1381, Time: 0.31s\n",
            "Epoch [201/250], Loss: 0.1132, Time: 0.31s\n",
            "Epoch [202/250], Loss: 0.1174, Time: 0.31s\n",
            "Epoch [203/250], Loss: 0.1139, Time: 0.31s\n",
            "Epoch [204/250], Loss: 0.1744, Time: 0.31s\n",
            "Epoch [205/250], Loss: 0.1390, Time: 0.31s\n",
            "Epoch [206/250], Loss: 0.1246, Time: 0.33s\n",
            "Epoch [207/250], Loss: 0.1329, Time: 0.31s\n",
            "Epoch [208/250], Loss: 0.1517, Time: 0.30s\n",
            "Epoch [209/250], Loss: 0.1185, Time: 0.31s\n",
            "Epoch [210/250], Loss: 0.1108, Time: 0.32s\n",
            "Epoch [211/250], Loss: 0.1208, Time: 0.31s\n",
            "Epoch [212/250], Loss: 0.1292, Time: 0.29s\n",
            "Epoch [213/250], Loss: 0.0966, Time: 0.30s\n",
            "Epoch [214/250], Loss: 0.1293, Time: 0.31s\n",
            "Epoch [215/250], Loss: 0.1682, Time: 0.33s\n",
            "Epoch [216/250], Loss: 0.1040, Time: 0.32s\n",
            "Epoch [217/250], Loss: 0.1095, Time: 0.31s\n",
            "Epoch [218/250], Loss: 0.1205, Time: 0.35s\n",
            "Epoch [219/250], Loss: 0.1335, Time: 0.34s\n",
            "Epoch [220/250], Loss: 0.1277, Time: 0.32s\n",
            "Epoch [221/250], Loss: 0.0999, Time: 0.32s\n",
            "Epoch [222/250], Loss: 0.1731, Time: 0.31s\n",
            "Epoch [223/250], Loss: 0.1447, Time: 0.31s\n",
            "Epoch [224/250], Loss: 0.1073, Time: 0.31s\n",
            "Epoch [225/250], Loss: 0.1044, Time: 0.32s\n",
            "Epoch [226/250], Loss: 0.1250, Time: 0.31s\n",
            "Epoch [227/250], Loss: 0.1371, Time: 0.30s\n",
            "Epoch [228/250], Loss: 0.1191, Time: 0.32s\n",
            "Epoch [229/250], Loss: 0.1049, Time: 0.32s\n",
            "Epoch [230/250], Loss: 0.1104, Time: 0.30s\n",
            "Epoch [231/250], Loss: 0.1121, Time: 0.32s\n",
            "Epoch [232/250], Loss: 0.0848, Time: 0.33s\n",
            "Epoch [233/250], Loss: 0.1121, Time: 0.32s\n",
            "Epoch [234/250], Loss: 0.1372, Time: 0.31s\n",
            "Epoch [235/250], Loss: 0.1338, Time: 0.31s\n",
            "Epoch [236/250], Loss: 0.1186, Time: 0.31s\n",
            "Epoch [237/250], Loss: 0.0878, Time: 0.31s\n",
            "Epoch [238/250], Loss: 0.1320, Time: 0.31s\n",
            "Epoch [239/250], Loss: 0.1146, Time: 0.31s\n",
            "Epoch [240/250], Loss: 0.1208, Time: 0.32s\n",
            "Epoch [241/250], Loss: 0.1671, Time: 0.32s\n",
            "Epoch [242/250], Loss: 0.1124, Time: 0.32s\n",
            "Epoch [243/250], Loss: 0.1264, Time: 0.30s\n",
            "Epoch [244/250], Loss: 0.1101, Time: 0.31s\n",
            "Epoch [245/250], Loss: 0.1094, Time: 0.32s\n",
            "Epoch [246/250], Loss: 0.1247, Time: 0.31s\n",
            "Epoch [247/250], Loss: 0.1517, Time: 0.31s\n",
            "Epoch [248/250], Loss: 0.1372, Time: 0.31s\n",
            "Epoch [249/250], Loss: 0.1246, Time: 0.32s\n",
            "Epoch [250/250], Loss: 0.1334, Time: 0.31s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bandingkan jumlah epochs."
      ],
      "metadata": {
        "id": "45ZQz20epBhn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Eksperimen 4: Learning Rates**\n"
      ],
      "metadata": {
        "id": "ZjbURzifpDq3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 4: Comparing Learning Rates\n",
        "learning_rates = [10, 1, 0.1, 0.01, 0.001, 0.0001]\n",
        "results_learning_rates = []\n",
        "for learning_rate in learning_rates:\n",
        "    accuracy = train_and_evaluate(hidden_layers=[32], activation_fn='relu', learning_rate=learning_rate, batch_size=32, epochs=50, dropout_rate=0.2, weight_decay=1e-4)\n",
        "    results_learning_rates.append({'learning_rate': learning_rate, 'accuracy': accuracy})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d8n4g1ZpFhb",
        "outputId": "c242a650-8247-4ce2-9747-ec7ff37c2b1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training with Parameters: Hidden Layers=[32], Activation=relu, LR=10, Batch Size=32, Epochs=50, Dropout=0.2, L2=0.0001\n",
            "Epoch [1/50], Loss: 144.4288, Time: 0.32s\n",
            "Epoch [2/50], Loss: 4.2785, Time: 0.33s\n",
            "Epoch [3/50], Loss: 3.4302, Time: 0.33s\n",
            "Epoch [4/50], Loss: 1.4975, Time: 0.31s\n",
            "Epoch [5/50], Loss: 1.1183, Time: 0.34s\n",
            "Epoch [6/50], Loss: 0.8256, Time: 0.32s\n",
            "Epoch [7/50], Loss: 2.1389, Time: 0.33s\n",
            "Epoch [8/50], Loss: 1.0431, Time: 0.31s\n",
            "Epoch [9/50], Loss: 1.2356, Time: 0.32s\n",
            "Epoch [10/50], Loss: 0.9683, Time: 0.32s\n",
            "Epoch [11/50], Loss: 1.2001, Time: 0.31s\n",
            "Epoch [12/50], Loss: 1.3447, Time: 0.31s\n",
            "Epoch [13/50], Loss: 0.8785, Time: 0.31s\n",
            "Epoch [14/50], Loss: 0.9395, Time: 0.31s\n",
            "Epoch [15/50], Loss: 0.8189, Time: 0.32s\n",
            "Epoch [16/50], Loss: 1.0372, Time: 0.30s\n",
            "Epoch [17/50], Loss: 0.9439, Time: 0.31s\n",
            "Epoch [18/50], Loss: 5.3227, Time: 0.31s\n",
            "Epoch [19/50], Loss: 3.1160, Time: 0.31s\n",
            "Epoch [20/50], Loss: 0.7962, Time: 0.31s\n",
            "Epoch [21/50], Loss: 0.7717, Time: 0.31s\n",
            "Epoch [22/50], Loss: 0.8500, Time: 0.32s\n",
            "Epoch [23/50], Loss: 0.9894, Time: 0.32s\n",
            "Epoch [24/50], Loss: 1.2308, Time: 0.32s\n",
            "Epoch [25/50], Loss: 0.8053, Time: 0.31s\n",
            "Epoch [26/50], Loss: 0.9613, Time: 0.31s\n",
            "Epoch [27/50], Loss: 0.9268, Time: 0.32s\n",
            "Epoch [28/50], Loss: 1.1474, Time: 0.32s\n",
            "Epoch [29/50], Loss: 0.7753, Time: 0.31s\n",
            "Epoch [30/50], Loss: 0.9600, Time: 0.31s\n",
            "Epoch [31/50], Loss: 1.0402, Time: 0.32s\n",
            "Epoch [32/50], Loss: 2.2844, Time: 0.32s\n",
            "Epoch [33/50], Loss: 13.7135, Time: 0.31s\n",
            "Epoch [34/50], Loss: 2.3316, Time: 0.32s\n",
            "Epoch [35/50], Loss: 1.1247, Time: 0.31s\n",
            "Epoch [36/50], Loss: 0.8402, Time: 0.33s\n",
            "Epoch [37/50], Loss: 1.0659, Time: 0.31s\n",
            "Epoch [38/50], Loss: 0.7977, Time: 0.32s\n",
            "Epoch [39/50], Loss: 0.7384, Time: 0.33s\n",
            "Epoch [40/50], Loss: 0.8197, Time: 0.34s\n",
            "Epoch [41/50], Loss: 0.8637, Time: 0.33s\n",
            "Epoch [42/50], Loss: 0.8207, Time: 0.33s\n",
            "Epoch [43/50], Loss: 1.1595, Time: 0.33s\n",
            "Epoch [44/50], Loss: 0.9023, Time: 0.32s\n",
            "Epoch [45/50], Loss: 1.1118, Time: 0.31s\n",
            "Epoch [46/50], Loss: 3.3058, Time: 0.31s\n",
            "Epoch [47/50], Loss: 1.1937, Time: 0.31s\n",
            "Epoch [48/50], Loss: 1.1323, Time: 0.30s\n",
            "Epoch [49/50], Loss: 2.5991, Time: 0.32s\n",
            "Epoch [50/50], Loss: 0.8710, Time: 0.35s\n",
            "\n",
            "Training with Parameters: Hidden Layers=[32], Activation=relu, LR=1, Batch Size=32, Epochs=50, Dropout=0.2, L2=0.0001\n",
            "Epoch [1/50], Loss: 3.3981, Time: 0.31s\n",
            "Epoch [2/50], Loss: 0.8235, Time: 0.31s\n",
            "Epoch [3/50], Loss: 0.5580, Time: 0.31s\n",
            "Epoch [4/50], Loss: 0.6683, Time: 0.31s\n",
            "Epoch [5/50], Loss: 0.6079, Time: 0.31s\n",
            "Epoch [6/50], Loss: 0.6108, Time: 0.31s\n",
            "Epoch [7/50], Loss: 0.6055, Time: 0.32s\n",
            "Epoch [8/50], Loss: 0.6227, Time: 0.31s\n",
            "Epoch [9/50], Loss: 0.5639, Time: 0.31s\n",
            "Epoch [10/50], Loss: 0.5822, Time: 0.31s\n",
            "Epoch [11/50], Loss: 0.6172, Time: 0.31s\n",
            "Epoch [12/50], Loss: 0.5902, Time: 0.32s\n",
            "Epoch [13/50], Loss: 0.5785, Time: 0.31s\n",
            "Epoch [14/50], Loss: 0.6126, Time: 0.31s\n",
            "Epoch [15/50], Loss: 0.6804, Time: 0.31s\n",
            "Epoch [16/50], Loss: 0.7708, Time: 0.32s\n",
            "Epoch [17/50], Loss: 0.7123, Time: 0.31s\n",
            "Epoch [18/50], Loss: 0.7161, Time: 0.31s\n",
            "Epoch [19/50], Loss: 0.7113, Time: 0.31s\n",
            "Epoch [20/50], Loss: 0.7361, Time: 0.31s\n",
            "Epoch [21/50], Loss: 0.7297, Time: 0.32s\n",
            "Epoch [22/50], Loss: 0.7206, Time: 0.31s\n",
            "Epoch [23/50], Loss: 0.7084, Time: 0.32s\n",
            "Epoch [24/50], Loss: 0.7238, Time: 0.31s\n",
            "Epoch [25/50], Loss: 0.7250, Time: 0.32s\n",
            "Epoch [26/50], Loss: 0.7443, Time: 0.32s\n",
            "Epoch [27/50], Loss: 0.7102, Time: 0.34s\n",
            "Epoch [28/50], Loss: 0.7234, Time: 0.33s\n",
            "Epoch [29/50], Loss: 0.7462, Time: 0.34s\n",
            "Epoch [30/50], Loss: 0.7043, Time: 0.33s\n",
            "Epoch [31/50], Loss: 0.7129, Time: 0.31s\n",
            "Epoch [32/50], Loss: 0.7345, Time: 0.31s\n",
            "Epoch [33/50], Loss: 0.7207, Time: 0.32s\n",
            "Epoch [34/50], Loss: 0.7095, Time: 0.31s\n",
            "Epoch [35/50], Loss: 0.7631, Time: 0.31s\n",
            "Epoch [36/50], Loss: 0.7291, Time: 0.31s\n",
            "Epoch [37/50], Loss: 0.7274, Time: 0.32s\n",
            "Epoch [38/50], Loss: 0.7574, Time: 0.33s\n",
            "Epoch [39/50], Loss: 0.7054, Time: 0.31s\n",
            "Epoch [40/50], Loss: 0.7378, Time: 0.32s\n",
            "Epoch [41/50], Loss: 0.7067, Time: 0.32s\n",
            "Epoch [42/50], Loss: 0.7194, Time: 0.32s\n",
            "Epoch [43/50], Loss: 0.7208, Time: 0.32s\n",
            "Epoch [44/50], Loss: 0.7439, Time: 0.32s\n",
            "Epoch [45/50], Loss: 0.7444, Time: 0.31s\n",
            "Epoch [46/50], Loss: 0.7440, Time: 0.32s\n",
            "Epoch [47/50], Loss: 0.7312, Time: 0.31s\n",
            "Epoch [48/50], Loss: 0.8593, Time: 0.31s\n",
            "Epoch [49/50], Loss: 0.7283, Time: 0.31s\n",
            "Epoch [50/50], Loss: 0.7313, Time: 0.32s\n",
            "\n",
            "Training with Parameters: Hidden Layers=[32], Activation=relu, LR=0.1, Batch Size=32, Epochs=50, Dropout=0.2, L2=0.0001\n",
            "Epoch [1/50], Loss: 0.4807, Time: 0.31s\n",
            "Epoch [2/50], Loss: 0.3632, Time: 0.32s\n",
            "Epoch [3/50], Loss: 0.3713, Time: 0.32s\n",
            "Epoch [4/50], Loss: 0.3438, Time: 0.30s\n",
            "Epoch [5/50], Loss: 0.3178, Time: 0.31s\n",
            "Epoch [6/50], Loss: 0.3618, Time: 0.32s\n",
            "Epoch [7/50], Loss: 0.3783, Time: 0.30s\n",
            "Epoch [8/50], Loss: 0.3280, Time: 0.30s\n",
            "Epoch [9/50], Loss: 0.3686, Time: 0.32s\n",
            "Epoch [10/50], Loss: 0.3435, Time: 0.31s\n",
            "Epoch [11/50], Loss: 0.3080, Time: 0.31s\n",
            "Epoch [12/50], Loss: 0.3055, Time: 0.32s\n",
            "Epoch [13/50], Loss: 0.3257, Time: 0.32s\n",
            "Epoch [14/50], Loss: 0.3309, Time: 0.32s\n",
            "Epoch [15/50], Loss: 0.2965, Time: 0.33s\n",
            "Epoch [16/50], Loss: 0.3065, Time: 0.33s\n",
            "Epoch [17/50], Loss: 0.2966, Time: 0.32s\n",
            "Epoch [18/50], Loss: 0.3270, Time: 0.32s\n",
            "Epoch [19/50], Loss: 0.3650, Time: 0.32s\n",
            "Epoch [20/50], Loss: 0.3309, Time: 0.32s\n",
            "Epoch [21/50], Loss: 0.3254, Time: 0.32s\n",
            "Epoch [22/50], Loss: 0.3263, Time: 0.32s\n",
            "Epoch [23/50], Loss: 0.3011, Time: 0.32s\n",
            "Epoch [24/50], Loss: 0.3207, Time: 0.31s\n",
            "Epoch [25/50], Loss: 0.3132, Time: 0.31s\n",
            "Epoch [26/50], Loss: 0.2793, Time: 0.32s\n",
            "Epoch [27/50], Loss: 0.2819, Time: 0.33s\n",
            "Epoch [28/50], Loss: 0.3139, Time: 0.31s\n",
            "Epoch [29/50], Loss: 0.2970, Time: 0.32s\n",
            "Epoch [30/50], Loss: 0.3443, Time: 0.32s\n",
            "Epoch [31/50], Loss: 0.3443, Time: 0.33s\n",
            "Epoch [32/50], Loss: 0.2623, Time: 0.32s\n",
            "Epoch [33/50], Loss: 0.2896, Time: 0.32s\n",
            "Epoch [34/50], Loss: 0.2782, Time: 0.35s\n",
            "Epoch [35/50], Loss: 0.2745, Time: 0.32s\n",
            "Epoch [36/50], Loss: 0.3268, Time: 0.32s\n",
            "Epoch [37/50], Loss: 0.3328, Time: 0.32s\n",
            "Epoch [38/50], Loss: 0.3124, Time: 0.32s\n",
            "Epoch [39/50], Loss: 0.2843, Time: 0.32s\n",
            "Epoch [40/50], Loss: 0.3010, Time: 0.31s\n",
            "Epoch [41/50], Loss: 0.2671, Time: 0.31s\n",
            "Epoch [42/50], Loss: 0.3207, Time: 0.32s\n",
            "Epoch [43/50], Loss: 0.3529, Time: 0.31s\n",
            "Epoch [44/50], Loss: 0.2832, Time: 0.31s\n",
            "Epoch [45/50], Loss: 0.3350, Time: 0.32s\n",
            "Epoch [46/50], Loss: 0.2870, Time: 0.31s\n",
            "Epoch [47/50], Loss: 0.2726, Time: 0.31s\n",
            "Epoch [48/50], Loss: 0.3163, Time: 0.33s\n",
            "Epoch [49/50], Loss: 0.2842, Time: 0.32s\n",
            "Epoch [50/50], Loss: 0.3320, Time: 0.33s\n",
            "\n",
            "Training with Parameters: Hidden Layers=[32], Activation=relu, LR=0.01, Batch Size=32, Epochs=50, Dropout=0.2, L2=0.0001\n",
            "Epoch [1/50], Loss: 0.4486, Time: 0.34s\n",
            "Epoch [2/50], Loss: 0.3352, Time: 0.35s\n",
            "Epoch [3/50], Loss: 0.3291, Time: 0.32s\n",
            "Epoch [4/50], Loss: 0.2980, Time: 0.31s\n",
            "Epoch [5/50], Loss: 0.2859, Time: 0.32s\n",
            "Epoch [6/50], Loss: 0.2820, Time: 0.32s\n",
            "Epoch [7/50], Loss: 0.2708, Time: 0.32s\n",
            "Epoch [8/50], Loss: 0.2633, Time: 0.30s\n",
            "Epoch [9/50], Loss: 0.2680, Time: 0.30s\n",
            "Epoch [10/50], Loss: 0.2734, Time: 0.32s\n",
            "Epoch [11/50], Loss: 0.2593, Time: 0.32s\n",
            "Epoch [12/50], Loss: 0.2605, Time: 0.31s\n",
            "Epoch [13/50], Loss: 0.2376, Time: 0.32s\n",
            "Epoch [14/50], Loss: 0.2380, Time: 0.31s\n",
            "Epoch [15/50], Loss: 0.2540, Time: 0.32s\n",
            "Epoch [16/50], Loss: 0.2433, Time: 0.32s\n",
            "Epoch [17/50], Loss: 0.2016, Time: 0.32s\n",
            "Epoch [18/50], Loss: 0.2531, Time: 0.31s\n",
            "Epoch [19/50], Loss: 0.2153, Time: 0.32s\n",
            "Epoch [20/50], Loss: 0.1967, Time: 0.32s\n",
            "Epoch [21/50], Loss: 0.1995, Time: 0.33s\n",
            "Epoch [22/50], Loss: 0.2189, Time: 0.32s\n",
            "Epoch [23/50], Loss: 0.1997, Time: 0.32s\n",
            "Epoch [24/50], Loss: 0.1971, Time: 0.32s\n",
            "Epoch [25/50], Loss: 0.2146, Time: 0.31s\n",
            "Epoch [26/50], Loss: 0.1641, Time: 0.32s\n",
            "Epoch [27/50], Loss: 0.2076, Time: 0.31s\n",
            "Epoch [28/50], Loss: 0.2065, Time: 0.32s\n",
            "Epoch [29/50], Loss: 0.1986, Time: 0.30s\n",
            "Epoch [30/50], Loss: 0.1885, Time: 0.31s\n",
            "Epoch [31/50], Loss: 0.1966, Time: 0.31s\n",
            "Epoch [32/50], Loss: 0.1990, Time: 0.31s\n",
            "Epoch [33/50], Loss: 0.1841, Time: 0.32s\n",
            "Epoch [34/50], Loss: 0.2033, Time: 0.33s\n",
            "Epoch [35/50], Loss: 0.1909, Time: 0.34s\n",
            "Epoch [36/50], Loss: 0.2200, Time: 0.33s\n",
            "Epoch [37/50], Loss: 0.2052, Time: 0.33s\n",
            "Epoch [38/50], Loss: 0.1902, Time: 0.34s\n",
            "Epoch [39/50], Loss: 0.1908, Time: 0.34s\n",
            "Epoch [40/50], Loss: 0.1997, Time: 0.31s\n",
            "Epoch [41/50], Loss: 0.1974, Time: 0.32s\n",
            "Epoch [42/50], Loss: 0.2101, Time: 0.31s\n",
            "Epoch [43/50], Loss: 0.1571, Time: 0.32s\n",
            "Epoch [44/50], Loss: 0.1856, Time: 0.31s\n",
            "Epoch [45/50], Loss: 0.1974, Time: 0.31s\n",
            "Epoch [46/50], Loss: 0.1709, Time: 0.31s\n",
            "Epoch [47/50], Loss: 0.1654, Time: 0.31s\n",
            "Epoch [48/50], Loss: 0.1527, Time: 0.31s\n",
            "Epoch [49/50], Loss: 0.1655, Time: 0.32s\n",
            "Epoch [50/50], Loss: 0.1598, Time: 0.31s\n",
            "\n",
            "Training with Parameters: Hidden Layers=[32], Activation=relu, LR=0.001, Batch Size=32, Epochs=50, Dropout=0.2, L2=0.0001\n",
            "Epoch [1/50], Loss: 0.7010, Time: 0.32s\n",
            "Epoch [2/50], Loss: 0.5446, Time: 0.34s\n",
            "Epoch [3/50], Loss: 0.4664, Time: 0.32s\n",
            "Epoch [4/50], Loss: 0.4294, Time: 0.31s\n",
            "Epoch [5/50], Loss: 0.3965, Time: 0.31s\n",
            "Epoch [6/50], Loss: 0.3832, Time: 0.32s\n",
            "Epoch [7/50], Loss: 0.3587, Time: 0.32s\n",
            "Epoch [8/50], Loss: 0.3632, Time: 0.31s\n",
            "Epoch [9/50], Loss: 0.3526, Time: 0.31s\n",
            "Epoch [10/50], Loss: 0.3440, Time: 0.31s\n",
            "Epoch [11/50], Loss: 0.3272, Time: 0.32s\n",
            "Epoch [12/50], Loss: 0.3256, Time: 0.32s\n",
            "Epoch [13/50], Loss: 0.3045, Time: 0.31s\n",
            "Epoch [14/50], Loss: 0.3190, Time: 0.34s\n",
            "Epoch [15/50], Loss: 0.3003, Time: 0.31s\n",
            "Epoch [16/50], Loss: 0.3313, Time: 0.30s\n",
            "Epoch [17/50], Loss: 0.2974, Time: 0.32s\n",
            "Epoch [18/50], Loss: 0.3138, Time: 0.32s\n",
            "Epoch [19/50], Loss: 0.3085, Time: 0.31s\n",
            "Epoch [20/50], Loss: 0.3101, Time: 0.32s\n",
            "Epoch [21/50], Loss: 0.2827, Time: 0.33s\n",
            "Epoch [22/50], Loss: 0.2943, Time: 0.34s\n",
            "Epoch [23/50], Loss: 0.3063, Time: 0.33s\n",
            "Epoch [24/50], Loss: 0.2916, Time: 0.34s\n",
            "Epoch [25/50], Loss: 0.2692, Time: 0.34s\n",
            "Epoch [26/50], Loss: 0.2805, Time: 0.31s\n",
            "Epoch [27/50], Loss: 0.2801, Time: 0.32s\n",
            "Epoch [28/50], Loss: 0.2645, Time: 0.32s\n",
            "Epoch [29/50], Loss: 0.2742, Time: 0.31s\n",
            "Epoch [30/50], Loss: 0.2772, Time: 0.33s\n",
            "Epoch [31/50], Loss: 0.2678, Time: 0.33s\n",
            "Epoch [32/50], Loss: 0.2564, Time: 0.31s\n",
            "Epoch [33/50], Loss: 0.2702, Time: 0.32s\n",
            "Epoch [34/50], Loss: 0.2620, Time: 0.32s\n",
            "Epoch [35/50], Loss: 0.2621, Time: 0.32s\n",
            "Epoch [36/50], Loss: 0.2697, Time: 0.31s\n",
            "Epoch [37/50], Loss: 0.2666, Time: 0.32s\n",
            "Epoch [38/50], Loss: 0.2518, Time: 0.32s\n",
            "Epoch [39/50], Loss: 0.2602, Time: 0.32s\n",
            "Epoch [40/50], Loss: 0.2503, Time: 0.36s\n",
            "Epoch [41/50], Loss: 0.2453, Time: 0.32s\n",
            "Epoch [42/50], Loss: 0.2541, Time: 0.32s\n",
            "Epoch [43/50], Loss: 0.2608, Time: 0.31s\n",
            "Epoch [44/50], Loss: 0.2361, Time: 0.32s\n",
            "Epoch [45/50], Loss: 0.2280, Time: 0.32s\n",
            "Epoch [46/50], Loss: 0.2369, Time: 0.31s\n",
            "Epoch [47/50], Loss: 0.2544, Time: 0.32s\n",
            "Epoch [48/50], Loss: 0.2337, Time: 0.31s\n",
            "Epoch [49/50], Loss: 0.2354, Time: 0.33s\n",
            "Epoch [50/50], Loss: 0.2286, Time: 0.32s\n",
            "\n",
            "Training with Parameters: Hidden Layers=[32], Activation=relu, LR=0.0001, Batch Size=32, Epochs=50, Dropout=0.2, L2=0.0001\n",
            "Epoch [1/50], Loss: 0.7272, Time: 0.31s\n",
            "Epoch [2/50], Loss: 0.7190, Time: 0.32s\n",
            "Epoch [3/50], Loss: 0.6962, Time: 0.31s\n",
            "Epoch [4/50], Loss: 0.6785, Time: 0.31s\n",
            "Epoch [5/50], Loss: 0.6679, Time: 0.32s\n",
            "Epoch [6/50], Loss: 0.6363, Time: 0.34s\n",
            "Epoch [7/50], Loss: 0.6277, Time: 0.34s\n",
            "Epoch [8/50], Loss: 0.6125, Time: 0.32s\n",
            "Epoch [9/50], Loss: 0.5985, Time: 0.35s\n",
            "Epoch [10/50], Loss: 0.5988, Time: 0.33s\n",
            "Epoch [11/50], Loss: 0.5716, Time: 0.35s\n",
            "Epoch [12/50], Loss: 0.5630, Time: 0.31s\n",
            "Epoch [13/50], Loss: 0.5589, Time: 0.32s\n",
            "Epoch [14/50], Loss: 0.5490, Time: 0.32s\n",
            "Epoch [15/50], Loss: 0.5336, Time: 0.32s\n",
            "Epoch [16/50], Loss: 0.5331, Time: 0.33s\n",
            "Epoch [17/50], Loss: 0.5182, Time: 0.31s\n",
            "Epoch [18/50], Loss: 0.5080, Time: 0.31s\n",
            "Epoch [19/50], Loss: 0.5011, Time: 0.32s\n",
            "Epoch [20/50], Loss: 0.4968, Time: 0.32s\n",
            "Epoch [21/50], Loss: 0.4878, Time: 0.31s\n",
            "Epoch [22/50], Loss: 0.4772, Time: 0.32s\n",
            "Epoch [23/50], Loss: 0.4790, Time: 0.32s\n",
            "Epoch [24/50], Loss: 0.4681, Time: 0.32s\n",
            "Epoch [25/50], Loss: 0.4645, Time: 0.32s\n",
            "Epoch [26/50], Loss: 0.4620, Time: 0.33s\n",
            "Epoch [27/50], Loss: 0.4648, Time: 0.33s\n",
            "Epoch [28/50], Loss: 0.4484, Time: 0.32s\n",
            "Epoch [29/50], Loss: 0.4452, Time: 0.32s\n",
            "Epoch [30/50], Loss: 0.4369, Time: 0.33s\n",
            "Epoch [31/50], Loss: 0.4404, Time: 0.31s\n",
            "Epoch [32/50], Loss: 0.4385, Time: 0.32s\n",
            "Epoch [33/50], Loss: 0.4272, Time: 0.32s\n",
            "Epoch [34/50], Loss: 0.4221, Time: 0.31s\n",
            "Epoch [35/50], Loss: 0.4221, Time: 0.33s\n",
            "Epoch [36/50], Loss: 0.4192, Time: 0.33s\n",
            "Epoch [37/50], Loss: 0.4108, Time: 0.32s\n",
            "Epoch [38/50], Loss: 0.4092, Time: 0.32s\n",
            "Epoch [39/50], Loss: 0.4058, Time: 0.32s\n",
            "Epoch [40/50], Loss: 0.4034, Time: 0.32s\n",
            "Epoch [41/50], Loss: 0.4100, Time: 0.32s\n",
            "Epoch [42/50], Loss: 0.4041, Time: 0.31s\n",
            "Epoch [43/50], Loss: 0.4049, Time: 0.34s\n",
            "Epoch [44/50], Loss: 0.3901, Time: 0.33s\n",
            "Epoch [45/50], Loss: 0.3822, Time: 0.33s\n",
            "Epoch [46/50], Loss: 0.3885, Time: 0.33s\n",
            "Epoch [47/50], Loss: 0.3838, Time: 0.33s\n",
            "Epoch [48/50], Loss: 0.3783, Time: 0.33s\n",
            "Epoch [49/50], Loss: 0.3710, Time: 0.32s\n",
            "Epoch [50/50], Loss: 0.3739, Time: 0.32s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bandingkan learning rate.\n"
      ],
      "metadata": {
        "id": "7EwLOnIppHP4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Eksperimen 5: Batch Sizes**"
      ],
      "metadata": {
        "id": "tUR3MtXCpIma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 5: Comparing Batch Sizes\n",
        "batch_sizes = [16, 32, 64, 128, 256, 512]\n",
        "results_batch_sizes = []\n",
        "for batch_size in batch_sizes:\n",
        "    accuracy = train_and_evaluate(hidden_layers=[32], activation_fn='relu', learning_rate=0.01, batch_size=batch_size, epochs=50, dropout_rate=0.2, weight_decay=1e-4)\n",
        "    results_batch_sizes.append({'batch_size': batch_size, 'accuracy': accuracy})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiMyyj9ypKLi",
        "outputId": "9ee4cd0d-1146-4010-c084-a13e5beb07e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training with Parameters: Hidden Layers=[32], Activation=relu, LR=0.01, Batch Size=16, Epochs=50, Dropout=0.2, L2=0.0001\n",
            "Epoch [1/50], Loss: 0.4045, Time: 0.38s\n",
            "Epoch [2/50], Loss: 0.3630, Time: 0.40s\n",
            "Epoch [3/50], Loss: 0.3428, Time: 0.38s\n",
            "Epoch [4/50], Loss: 0.3474, Time: 0.38s\n",
            "Epoch [5/50], Loss: 0.3545, Time: 0.38s\n",
            "Epoch [6/50], Loss: 0.3338, Time: 0.38s\n",
            "Epoch [7/50], Loss: 0.3235, Time: 0.39s\n",
            "Epoch [8/50], Loss: 0.2881, Time: 0.38s\n",
            "Epoch [9/50], Loss: 0.3243, Time: 0.37s\n",
            "Epoch [10/50], Loss: 0.3513, Time: 0.39s\n",
            "Epoch [11/50], Loss: 0.2565, Time: 0.39s\n",
            "Epoch [12/50], Loss: 0.2971, Time: 0.38s\n",
            "Epoch [13/50], Loss: 0.2941, Time: 0.38s\n",
            "Epoch [14/50], Loss: 0.2714, Time: 0.39s\n",
            "Epoch [15/50], Loss: 0.2910, Time: 0.39s\n",
            "Epoch [16/50], Loss: 0.2572, Time: 0.38s\n",
            "Epoch [17/50], Loss: 0.2932, Time: 0.38s\n",
            "Epoch [18/50], Loss: 0.2750, Time: 0.39s\n",
            "Epoch [19/50], Loss: 0.2897, Time: 0.40s\n",
            "Epoch [20/50], Loss: 0.2749, Time: 0.39s\n",
            "Epoch [21/50], Loss: 0.2628, Time: 0.39s\n",
            "Epoch [22/50], Loss: 0.2449, Time: 0.39s\n",
            "Epoch [23/50], Loss: 0.2728, Time: 0.38s\n",
            "Epoch [24/50], Loss: 0.2444, Time: 0.40s\n",
            "Epoch [25/50], Loss: 0.2565, Time: 0.40s\n",
            "Epoch [26/50], Loss: 0.2482, Time: 0.40s\n",
            "Epoch [27/50], Loss: 0.2494, Time: 0.41s\n",
            "Epoch [28/50], Loss: 0.2413, Time: 0.41s\n",
            "Epoch [29/50], Loss: 0.2495, Time: 0.38s\n",
            "Epoch [30/50], Loss: 0.2243, Time: 0.39s\n",
            "Epoch [31/50], Loss: 0.2330, Time: 0.38s\n",
            "Epoch [32/50], Loss: 0.2482, Time: 0.38s\n",
            "Epoch [33/50], Loss: 0.2628, Time: 0.38s\n",
            "Epoch [34/50], Loss: 0.2302, Time: 0.38s\n",
            "Epoch [35/50], Loss: 0.2002, Time: 0.39s\n",
            "Epoch [36/50], Loss: 0.2332, Time: 0.38s\n",
            "Epoch [37/50], Loss: 0.2177, Time: 0.38s\n",
            "Epoch [38/50], Loss: 0.2770, Time: 0.39s\n",
            "Epoch [39/50], Loss: 0.2252, Time: 0.38s\n",
            "Epoch [40/50], Loss: 0.2280, Time: 0.38s\n",
            "Epoch [41/50], Loss: 0.2026, Time: 0.39s\n",
            "Epoch [42/50], Loss: 0.2094, Time: 0.39s\n",
            "Epoch [43/50], Loss: 0.2474, Time: 0.39s\n",
            "Epoch [44/50], Loss: 0.2481, Time: 0.39s\n",
            "Epoch [45/50], Loss: 0.2543, Time: 0.39s\n",
            "Epoch [46/50], Loss: 0.2521, Time: 0.40s\n",
            "Epoch [47/50], Loss: 0.2335, Time: 0.39s\n",
            "Epoch [48/50], Loss: 0.2298, Time: 0.39s\n",
            "Epoch [49/50], Loss: 0.2318, Time: 0.38s\n",
            "Epoch [50/50], Loss: 0.2735, Time: 0.39s\n",
            "\n",
            "Training with Parameters: Hidden Layers=[32], Activation=relu, LR=0.01, Batch Size=32, Epochs=50, Dropout=0.2, L2=0.0001\n",
            "Epoch [1/50], Loss: 0.4701, Time: 0.32s\n",
            "Epoch [2/50], Loss: 0.3225, Time: 0.32s\n",
            "Epoch [3/50], Loss: 0.3155, Time: 0.33s\n",
            "Epoch [4/50], Loss: 0.2964, Time: 0.33s\n",
            "Epoch [5/50], Loss: 0.2808, Time: 0.33s\n",
            "Epoch [6/50], Loss: 0.2703, Time: 0.34s\n",
            "Epoch [7/50], Loss: 0.3010, Time: 0.35s\n",
            "Epoch [8/50], Loss: 0.2671, Time: 0.36s\n",
            "Epoch [9/50], Loss: 0.2313, Time: 0.34s\n",
            "Epoch [10/50], Loss: 0.2497, Time: 0.34s\n",
            "Epoch [11/50], Loss: 0.2409, Time: 0.32s\n",
            "Epoch [12/50], Loss: 0.2448, Time: 0.32s\n",
            "Epoch [13/50], Loss: 0.2370, Time: 0.32s\n",
            "Epoch [14/50], Loss: 0.2256, Time: 0.32s\n",
            "Epoch [15/50], Loss: 0.2314, Time: 0.33s\n",
            "Epoch [16/50], Loss: 0.2348, Time: 0.34s\n",
            "Epoch [17/50], Loss: 0.2480, Time: 0.33s\n",
            "Epoch [18/50], Loss: 0.2470, Time: 0.34s\n",
            "Epoch [19/50], Loss: 0.2373, Time: 0.32s\n",
            "Epoch [20/50], Loss: 0.1946, Time: 0.34s\n",
            "Epoch [21/50], Loss: 0.2172, Time: 0.33s\n",
            "Epoch [22/50], Loss: 0.2198, Time: 0.32s\n",
            "Epoch [23/50], Loss: 0.2276, Time: 0.34s\n",
            "Epoch [24/50], Loss: 0.2480, Time: 0.33s\n",
            "Epoch [25/50], Loss: 0.2070, Time: 0.33s\n",
            "Epoch [26/50], Loss: 0.1862, Time: 0.32s\n",
            "Epoch [27/50], Loss: 0.2262, Time: 0.33s\n",
            "Epoch [28/50], Loss: 0.2044, Time: 0.32s\n",
            "Epoch [29/50], Loss: 0.2160, Time: 0.32s\n",
            "Epoch [30/50], Loss: 0.1918, Time: 0.33s\n",
            "Epoch [31/50], Loss: 0.2093, Time: 0.32s\n",
            "Epoch [32/50], Loss: 0.1749, Time: 0.33s\n",
            "Epoch [33/50], Loss: 0.1682, Time: 0.33s\n",
            "Epoch [34/50], Loss: 0.1892, Time: 0.32s\n",
            "Epoch [35/50], Loss: 0.2251, Time: 0.34s\n",
            "Epoch [36/50], Loss: 0.1865, Time: 0.33s\n",
            "Epoch [37/50], Loss: 0.1947, Time: 0.34s\n",
            "Epoch [38/50], Loss: 0.1850, Time: 0.33s\n",
            "Epoch [39/50], Loss: 0.1866, Time: 0.31s\n",
            "Epoch [40/50], Loss: 0.1845, Time: 0.33s\n",
            "Epoch [41/50], Loss: 0.1971, Time: 0.34s\n",
            "Epoch [42/50], Loss: 0.1845, Time: 0.34s\n",
            "Epoch [43/50], Loss: 0.1516, Time: 0.34s\n",
            "Epoch [44/50], Loss: 0.1700, Time: 0.35s\n",
            "Epoch [45/50], Loss: 0.1684, Time: 0.35s\n",
            "Epoch [46/50], Loss: 0.1633, Time: 0.33s\n",
            "Epoch [47/50], Loss: 0.2144, Time: 0.34s\n",
            "Epoch [48/50], Loss: 0.1708, Time: 0.33s\n",
            "Epoch [49/50], Loss: 0.1663, Time: 0.34s\n",
            "Epoch [50/50], Loss: 0.1802, Time: 0.33s\n",
            "\n",
            "Training with Parameters: Hidden Layers=[32], Activation=relu, LR=0.01, Batch Size=64, Epochs=50, Dropout=0.2, L2=0.0001\n",
            "Epoch [1/50], Loss: 0.5206, Time: 0.30s\n",
            "Epoch [2/50], Loss: 0.3359, Time: 0.30s\n",
            "Epoch [3/50], Loss: 0.3230, Time: 0.30s\n",
            "Epoch [4/50], Loss: 0.2831, Time: 0.30s\n",
            "Epoch [5/50], Loss: 0.2685, Time: 0.31s\n",
            "Epoch [6/50], Loss: 0.2734, Time: 0.30s\n",
            "Epoch [7/50], Loss: 0.2794, Time: 0.31s\n",
            "Epoch [8/50], Loss: 0.2570, Time: 0.30s\n",
            "Epoch [9/50], Loss: 0.2516, Time: 0.30s\n",
            "Epoch [10/50], Loss: 0.2215, Time: 0.30s\n",
            "Epoch [11/50], Loss: 0.2253, Time: 0.30s\n",
            "Epoch [12/50], Loss: 0.2183, Time: 0.30s\n",
            "Epoch [13/50], Loss: 0.2413, Time: 0.30s\n",
            "Epoch [14/50], Loss: 0.2285, Time: 0.31s\n",
            "Epoch [15/50], Loss: 0.2065, Time: 0.30s\n",
            "Epoch [16/50], Loss: 0.2327, Time: 0.35s\n",
            "Epoch [17/50], Loss: 0.1986, Time: 0.30s\n",
            "Epoch [18/50], Loss: 0.2064, Time: 0.30s\n",
            "Epoch [19/50], Loss: 0.2019, Time: 0.30s\n",
            "Epoch [20/50], Loss: 0.1929, Time: 0.30s\n",
            "Epoch [21/50], Loss: 0.2017, Time: 0.29s\n",
            "Epoch [22/50], Loss: 0.1882, Time: 0.30s\n",
            "Epoch [23/50], Loss: 0.1878, Time: 0.30s\n",
            "Epoch [24/50], Loss: 0.2097, Time: 0.30s\n",
            "Epoch [25/50], Loss: 0.1906, Time: 0.30s\n",
            "Epoch [26/50], Loss: 0.1832, Time: 0.30s\n",
            "Epoch [27/50], Loss: 0.1642, Time: 0.31s\n",
            "Epoch [28/50], Loss: 0.1983, Time: 0.33s\n",
            "Epoch [29/50], Loss: 0.1717, Time: 0.30s\n",
            "Epoch [30/50], Loss: 0.1840, Time: 0.32s\n",
            "Epoch [31/50], Loss: 0.1550, Time: 0.32s\n",
            "Epoch [32/50], Loss: 0.1806, Time: 0.30s\n",
            "Epoch [33/50], Loss: 0.1854, Time: 0.30s\n",
            "Epoch [34/50], Loss: 0.1765, Time: 0.30s\n",
            "Epoch [35/50], Loss: 0.1706, Time: 0.30s\n",
            "Epoch [36/50], Loss: 0.1541, Time: 0.30s\n",
            "Epoch [37/50], Loss: 0.1364, Time: 0.30s\n",
            "Epoch [38/50], Loss: 0.1723, Time: 0.31s\n",
            "Epoch [39/50], Loss: 0.1569, Time: 0.30s\n",
            "Epoch [40/50], Loss: 0.1659, Time: 0.30s\n",
            "Epoch [41/50], Loss: 0.1737, Time: 0.30s\n",
            "Epoch [42/50], Loss: 0.1674, Time: 0.30s\n",
            "Epoch [43/50], Loss: 0.1447, Time: 0.30s\n",
            "Epoch [44/50], Loss: 0.1445, Time: 0.30s\n",
            "Epoch [45/50], Loss: 0.1544, Time: 0.30s\n",
            "Epoch [46/50], Loss: 0.1649, Time: 0.31s\n",
            "Epoch [47/50], Loss: 0.1437, Time: 0.31s\n",
            "Epoch [48/50], Loss: 0.1566, Time: 0.31s\n",
            "Epoch [49/50], Loss: 0.1538, Time: 0.29s\n",
            "Epoch [50/50], Loss: 0.1563, Time: 0.30s\n",
            "\n",
            "Training with Parameters: Hidden Layers=[32], Activation=relu, LR=0.01, Batch Size=128, Epochs=50, Dropout=0.2, L2=0.0001\n",
            "Epoch [1/50], Loss: 0.6175, Time: 0.29s\n",
            "Epoch [2/50], Loss: 0.3818, Time: 0.29s\n",
            "Epoch [3/50], Loss: 0.3326, Time: 0.30s\n",
            "Epoch [4/50], Loss: 0.3212, Time: 0.30s\n",
            "Epoch [5/50], Loss: 0.3026, Time: 0.29s\n",
            "Epoch [6/50], Loss: 0.2999, Time: 0.29s\n",
            "Epoch [7/50], Loss: 0.2722, Time: 0.29s\n",
            "Epoch [8/50], Loss: 0.2880, Time: 0.29s\n",
            "Epoch [9/50], Loss: 0.2736, Time: 0.29s\n",
            "Epoch [10/50], Loss: 0.2507, Time: 0.29s\n",
            "Epoch [11/50], Loss: 0.2639, Time: 0.29s\n",
            "Epoch [12/50], Loss: 0.2365, Time: 0.29s\n",
            "Epoch [13/50], Loss: 0.2437, Time: 0.30s\n",
            "Epoch [14/50], Loss: 0.2236, Time: 0.28s\n",
            "Epoch [15/50], Loss: 0.2413, Time: 0.29s\n",
            "Epoch [16/50], Loss: 0.2167, Time: 0.30s\n",
            "Epoch [17/50], Loss: 0.2193, Time: 0.30s\n",
            "Epoch [18/50], Loss: 0.2009, Time: 0.30s\n",
            "Epoch [19/50], Loss: 0.2043, Time: 0.31s\n",
            "Epoch [20/50], Loss: 0.1994, Time: 0.29s\n",
            "Epoch [21/50], Loss: 0.2057, Time: 0.30s\n",
            "Epoch [22/50], Loss: 0.1984, Time: 0.29s\n",
            "Epoch [23/50], Loss: 0.1896, Time: 0.29s\n",
            "Epoch [24/50], Loss: 0.2011, Time: 0.29s\n",
            "Epoch [25/50], Loss: 0.1780, Time: 0.29s\n",
            "Epoch [26/50], Loss: 0.2037, Time: 0.29s\n",
            "Epoch [27/50], Loss: 0.1938, Time: 0.29s\n",
            "Epoch [28/50], Loss: 0.2007, Time: 0.29s\n",
            "Epoch [29/50], Loss: 0.1681, Time: 0.29s\n",
            "Epoch [30/50], Loss: 0.1798, Time: 0.29s\n",
            "Epoch [31/50], Loss: 0.1769, Time: 0.30s\n",
            "Epoch [32/50], Loss: 0.1809, Time: 0.28s\n",
            "Epoch [33/50], Loss: 0.1696, Time: 0.29s\n",
            "Epoch [34/50], Loss: 0.1780, Time: 0.29s\n",
            "Epoch [35/50], Loss: 0.1566, Time: 0.28s\n",
            "Epoch [36/50], Loss: 0.1696, Time: 0.28s\n",
            "Epoch [37/50], Loss: 0.1700, Time: 0.30s\n",
            "Epoch [38/50], Loss: 0.1856, Time: 0.28s\n",
            "Epoch [39/50], Loss: 0.1588, Time: 0.29s\n",
            "Epoch [40/50], Loss: 0.1688, Time: 0.31s\n",
            "Epoch [41/50], Loss: 0.1891, Time: 0.29s\n",
            "Epoch [42/50], Loss: 0.1676, Time: 0.29s\n",
            "Epoch [43/50], Loss: 0.1611, Time: 0.28s\n",
            "Epoch [44/50], Loss: 0.1493, Time: 0.28s\n",
            "Epoch [45/50], Loss: 0.1914, Time: 0.28s\n",
            "Epoch [46/50], Loss: 0.1713, Time: 0.28s\n",
            "Epoch [47/50], Loss: 0.1645, Time: 0.30s\n",
            "Epoch [48/50], Loss: 0.1884, Time: 0.29s\n",
            "Epoch [49/50], Loss: 0.1661, Time: 0.29s\n",
            "Epoch [50/50], Loss: 0.1660, Time: 0.28s\n",
            "\n",
            "Training with Parameters: Hidden Layers=[32], Activation=relu, LR=0.01, Batch Size=256, Epochs=50, Dropout=0.2, L2=0.0001\n",
            "Epoch [1/50], Loss: 0.6107, Time: 0.27s\n",
            "Epoch [2/50], Loss: 0.4512, Time: 0.28s\n",
            "Epoch [3/50], Loss: 0.3394, Time: 0.27s\n",
            "Epoch [4/50], Loss: 0.3330, Time: 0.27s\n",
            "Epoch [5/50], Loss: 0.3278, Time: 0.26s\n",
            "Epoch [6/50], Loss: 0.3104, Time: 0.30s\n",
            "Epoch [7/50], Loss: 0.2723, Time: 0.28s\n",
            "Epoch [8/50], Loss: 0.2752, Time: 0.27s\n",
            "Epoch [9/50], Loss: 0.2670, Time: 0.28s\n",
            "Epoch [10/50], Loss: 0.3087, Time: 0.28s\n",
            "Epoch [11/50], Loss: 0.2756, Time: 0.28s\n",
            "Epoch [12/50], Loss: 0.2840, Time: 0.28s\n",
            "Epoch [13/50], Loss: 0.2930, Time: 0.27s\n",
            "Epoch [14/50], Loss: 0.2463, Time: 0.28s\n",
            "Epoch [15/50], Loss: 0.2717, Time: 0.27s\n",
            "Epoch [16/50], Loss: 0.2472, Time: 0.27s\n",
            "Epoch [17/50], Loss: 0.2427, Time: 0.28s\n",
            "Epoch [18/50], Loss: 0.2405, Time: 0.27s\n",
            "Epoch [19/50], Loss: 0.2520, Time: 0.28s\n",
            "Epoch [20/50], Loss: 0.2369, Time: 0.28s\n",
            "Epoch [21/50], Loss: 0.2280, Time: 0.28s\n",
            "Epoch [22/50], Loss: 0.2042, Time: 0.27s\n",
            "Epoch [23/50], Loss: 0.2190, Time: 0.27s\n",
            "Epoch [24/50], Loss: 0.2082, Time: 0.27s\n",
            "Epoch [25/50], Loss: 0.2677, Time: 0.27s\n",
            "Epoch [26/50], Loss: 0.2399, Time: 0.27s\n",
            "Epoch [27/50], Loss: 0.2207, Time: 0.28s\n",
            "Epoch [28/50], Loss: 0.2112, Time: 0.27s\n",
            "Epoch [29/50], Loss: 0.2062, Time: 0.28s\n",
            "Epoch [30/50], Loss: 0.2006, Time: 0.27s\n",
            "Epoch [31/50], Loss: 0.2035, Time: 0.28s\n",
            "Epoch [32/50], Loss: 0.2058, Time: 0.27s\n",
            "Epoch [33/50], Loss: 0.1966, Time: 0.27s\n",
            "Epoch [34/50], Loss: 0.2371, Time: 0.28s\n",
            "Epoch [35/50], Loss: 0.1738, Time: 0.27s\n",
            "Epoch [36/50], Loss: 0.2440, Time: 0.28s\n",
            "Epoch [37/50], Loss: 0.1763, Time: 0.28s\n",
            "Epoch [38/50], Loss: 0.1893, Time: 0.29s\n",
            "Epoch [39/50], Loss: 0.1776, Time: 0.27s\n",
            "Epoch [40/50], Loss: 0.1963, Time: 0.27s\n",
            "Epoch [41/50], Loss: 0.1616, Time: 0.27s\n",
            "Epoch [42/50], Loss: 0.1836, Time: 0.91s\n",
            "Epoch [43/50], Loss: 0.1420, Time: 0.28s\n",
            "Epoch [44/50], Loss: 0.2003, Time: 0.26s\n",
            "Epoch [45/50], Loss: 0.1762, Time: 0.29s\n",
            "Epoch [46/50], Loss: 0.1596, Time: 0.29s\n",
            "Epoch [47/50], Loss: 0.1573, Time: 0.29s\n",
            "Epoch [48/50], Loss: 0.1512, Time: 0.29s\n",
            "Epoch [49/50], Loss: 0.1939, Time: 0.30s\n",
            "Epoch [50/50], Loss: 0.1624, Time: 0.29s\n",
            "\n",
            "Training with Parameters: Hidden Layers=[32], Activation=relu, LR=0.01, Batch Size=512, Epochs=50, Dropout=0.2, L2=0.0001\n",
            "Epoch [1/50], Loss: 0.7286, Time: 0.29s\n",
            "Epoch [2/50], Loss: 0.5359, Time: 0.28s\n",
            "Epoch [3/50], Loss: 0.4490, Time: 0.28s\n",
            "Epoch [4/50], Loss: 0.3908, Time: 0.27s\n",
            "Epoch [5/50], Loss: 0.3697, Time: 0.27s\n",
            "Epoch [6/50], Loss: 0.3535, Time: 0.29s\n",
            "Epoch [7/50], Loss: 0.3357, Time: 0.29s\n",
            "Epoch [8/50], Loss: 0.3271, Time: 0.28s\n",
            "Epoch [9/50], Loss: 0.3124, Time: 0.27s\n",
            "Epoch [10/50], Loss: 0.2993, Time: 0.28s\n",
            "Epoch [11/50], Loss: 0.3122, Time: 0.28s\n",
            "Epoch [12/50], Loss: 0.2988, Time: 0.28s\n",
            "Epoch [13/50], Loss: 0.2973, Time: 0.27s\n",
            "Epoch [14/50], Loss: 0.2860, Time: 0.27s\n",
            "Epoch [15/50], Loss: 0.2961, Time: 0.29s\n",
            "Epoch [16/50], Loss: 0.2659, Time: 0.27s\n",
            "Epoch [17/50], Loss: 0.2762, Time: 0.29s\n",
            "Epoch [18/50], Loss: 0.2666, Time: 0.28s\n",
            "Epoch [19/50], Loss: 0.2648, Time: 0.27s\n",
            "Epoch [20/50], Loss: 0.2609, Time: 0.28s\n",
            "Epoch [21/50], Loss: 0.2488, Time: 0.27s\n",
            "Epoch [22/50], Loss: 0.2543, Time: 0.29s\n",
            "Epoch [23/50], Loss: 0.2525, Time: 0.27s\n",
            "Epoch [24/50], Loss: 0.2547, Time: 0.27s\n",
            "Epoch [25/50], Loss: 0.2538, Time: 0.27s\n",
            "Epoch [26/50], Loss: 0.2379, Time: 0.29s\n",
            "Epoch [27/50], Loss: 0.2493, Time: 0.28s\n",
            "Epoch [28/50], Loss: 0.2358, Time: 0.28s\n",
            "Epoch [29/50], Loss: 0.2347, Time: 0.29s\n",
            "Epoch [30/50], Loss: 0.2279, Time: 0.28s\n",
            "Epoch [31/50], Loss: 0.2363, Time: 0.27s\n",
            "Epoch [32/50], Loss: 0.2290, Time: 0.28s\n",
            "Epoch [33/50], Loss: 0.2246, Time: 0.28s\n",
            "Epoch [34/50], Loss: 0.2222, Time: 0.28s\n",
            "Epoch [35/50], Loss: 0.2157, Time: 0.27s\n",
            "Epoch [36/50], Loss: 0.2270, Time: 0.29s\n",
            "Epoch [37/50], Loss: 0.2170, Time: 0.28s\n",
            "Epoch [38/50], Loss: 0.2163, Time: 0.29s\n",
            "Epoch [39/50], Loss: 0.2117, Time: 0.32s\n",
            "Epoch [40/50], Loss: 0.1949, Time: 0.29s\n",
            "Epoch [41/50], Loss: 0.1927, Time: 0.30s\n",
            "Epoch [42/50], Loss: 0.1998, Time: 0.29s\n",
            "Epoch [43/50], Loss: 0.2025, Time: 0.30s\n",
            "Epoch [44/50], Loss: 0.1825, Time: 0.27s\n",
            "Epoch [45/50], Loss: 0.2061, Time: 0.29s\n",
            "Epoch [46/50], Loss: 0.1785, Time: 0.28s\n",
            "Epoch [47/50], Loss: 0.1882, Time: 0.27s\n",
            "Epoch [48/50], Loss: 0.1796, Time: 0.29s\n",
            "Epoch [49/50], Loss: 0.1840, Time: 0.28s\n",
            "Epoch [50/50], Loss: 0.1631, Time: 0.28s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Bandingkan ukuran batch."
      ],
      "metadata": {
        "id": "MDh-__eLpPdh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Simpan Hasil Eksperimen**\n"
      ],
      "metadata": {
        "id": "V7kZm5QxpSg4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save Results to CSV\n",
        "hidden_layers_df = pd.DataFrame(results_hidden_layers)\n",
        "activation_functions_df = pd.DataFrame(results_activation_functions)\n",
        "epochs_df = pd.DataFrame(results_epochs)\n",
        "learning_rates_df = pd.DataFrame(results_learning_rates)\n",
        "batch_sizes_df = pd.DataFrame(results_batch_sizes)\n",
        "\n",
        "hidden_layers_df.to_csv('mlp_hidden_layers_results.csv', index=False)\n",
        "activation_functions_df.to_csv('mlp_activation_functions_results.csv', index=False)\n",
        "epochs_df.to_csv('mlp_epochs_results.csv', index=False)\n",
        "learning_rates_df.to_csv('mlp_learning_rates_results.csv', index=False)\n",
        "batch_sizes_df.to_csv('mlp_batch_sizes_results.csv', index=False)"
      ],
      "metadata": {
        "id": "1DB4kU3KpRp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Simpan hasil eksperimen ke file CSV untuk analisis lebih lanjut."
      ],
      "metadata": {
        "id": "f9UdoSxgpWxp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model dengan HyperParameter Optimal"
      ],
      "metadata": {
        "id": "YKTjx8n4zwj7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Define function to train and evaluate the model with L1/L2 regularization\n",
        "def train_and_evaluate(hidden_layers, activation_fn, learning_rate, batch_size, epochs, dropout_rate, weight_decay):\n",
        "    # Initialize dataset and dataloaders\n",
        "    train_dataset = CustomDataset(X_train, y_train)\n",
        "    test_dataset = CustomDataset(X_test, y_test)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=8, pin_memory=True)\n",
        "\n",
        "    # Initialize model, loss function, and optimizer\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = MLPModel(input_size=X_train.shape[1], hidden_layers=hidden_layers, activation_fn=activation_fn, dropout_rate=dropout_rate).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()  # Cross-entropy loss for classification\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)  # L2 regularization via weight_decay\n",
        "\n",
        "    # Training loop\n",
        "    epoch_losses = []\n",
        "    for epoch in range(epochs):\n",
        "        start_time = time.time()\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for features, labels in train_loader:\n",
        "            features, labels = features.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(features)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        epoch_time = time.time() - start_time\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        epoch_losses.append(avg_loss)\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}, Time: {epoch_time:.2f}s\")\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for features, labels in test_loader:\n",
        "            features, labels = features.to(device), labels.to(device)\n",
        "            outputs = model(features)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = correct / total * 100\n",
        "    return accuracy, epoch_losses\n",
        "\n",
        "# Train model with optimal hyperparameters\n",
        "optimal_params = {\n",
        "    'hidden_layers': [32],\n",
        "    'activation_fn': 'tanh',\n",
        "    'learning_rate': 0.01,\n",
        "    'batch_size': 32,\n",
        "    'epochs': 150,\n",
        "    'dropout_rate': 0.2,\n",
        "    'weight_decay': 1e-4\n",
        "}\n",
        "\n",
        "accuracy, epoch_losses = train_and_evaluate(**optimal_params)\n",
        "\n",
        "# Print final accuracy\n",
        "print(f\"\\nFinal Model Accuracy with Optimal Hyperparameters: {accuracy:.2f}%\")\n",
        "\n",
        "# Visualize Training Loss\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(1, len(epoch_losses) + 1), epoch_losses, marker='o')\n",
        "plt.title('Training Loss Over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "y9A0syeDzv5n",
        "outputId": "430ea76f-453d-49db-d9e9-f034331e3809"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/150], Loss: 0.3912, Time: 0.48s\n",
            "Epoch [2/150], Loss: 0.3343, Time: 0.21s\n",
            "Epoch [3/150], Loss: 0.3287, Time: 0.19s\n",
            "Epoch [4/150], Loss: 0.3250, Time: 0.19s\n",
            "Epoch [5/150], Loss: 0.3177, Time: 0.21s\n",
            "Epoch [6/150], Loss: 0.3113, Time: 0.19s\n",
            "Epoch [7/150], Loss: 0.2887, Time: 0.19s\n",
            "Epoch [8/150], Loss: 0.2692, Time: 0.20s\n",
            "Epoch [9/150], Loss: 0.2873, Time: 0.20s\n",
            "Epoch [10/150], Loss: 0.2850, Time: 0.20s\n",
            "Epoch [11/150], Loss: 0.2481, Time: 0.21s\n",
            "Epoch [12/150], Loss: 0.2621, Time: 0.20s\n",
            "Epoch [13/150], Loss: 0.2496, Time: 0.20s\n",
            "Epoch [14/150], Loss: 0.2316, Time: 0.19s\n",
            "Epoch [15/150], Loss: 0.2253, Time: 0.20s\n",
            "Epoch [16/150], Loss: 0.2606, Time: 0.20s\n",
            "Epoch [17/150], Loss: 0.2288, Time: 0.20s\n",
            "Epoch [18/150], Loss: 0.2100, Time: 0.20s\n",
            "Epoch [19/150], Loss: 0.2131, Time: 0.20s\n",
            "Epoch [20/150], Loss: 0.1990, Time: 0.21s\n",
            "Epoch [21/150], Loss: 0.1978, Time: 0.19s\n",
            "Epoch [22/150], Loss: 0.1918, Time: 0.20s\n",
            "Epoch [23/150], Loss: 0.1718, Time: 0.20s\n",
            "Epoch [24/150], Loss: 0.1785, Time: 0.20s\n",
            "Epoch [25/150], Loss: 0.1902, Time: 0.21s\n",
            "Epoch [26/150], Loss: 0.1987, Time: 0.21s\n",
            "Epoch [27/150], Loss: 0.1667, Time: 0.20s\n",
            "Epoch [28/150], Loss: 0.1871, Time: 0.20s\n",
            "Epoch [29/150], Loss: 0.1580, Time: 0.20s\n",
            "Epoch [30/150], Loss: 0.2069, Time: 0.20s\n",
            "Epoch [31/150], Loss: 0.1665, Time: 0.21s\n",
            "Epoch [32/150], Loss: 0.1628, Time: 0.21s\n",
            "Epoch [33/150], Loss: 0.1423, Time: 0.21s\n",
            "Epoch [34/150], Loss: 0.1627, Time: 0.21s\n",
            "Epoch [35/150], Loss: 0.1454, Time: 0.22s\n",
            "Epoch [36/150], Loss: 0.1813, Time: 0.20s\n",
            "Epoch [37/150], Loss: 0.1444, Time: 0.20s\n",
            "Epoch [38/150], Loss: 0.1646, Time: 0.20s\n",
            "Epoch [39/150], Loss: 0.1548, Time: 0.19s\n",
            "Epoch [40/150], Loss: 0.1918, Time: 0.21s\n",
            "Epoch [41/150], Loss: 0.1692, Time: 0.20s\n",
            "Epoch [42/150], Loss: 0.1657, Time: 0.20s\n",
            "Epoch [43/150], Loss: 0.1468, Time: 0.41s\n",
            "Epoch [44/150], Loss: 0.1521, Time: 0.20s\n",
            "Epoch [45/150], Loss: 0.1444, Time: 0.21s\n",
            "Epoch [46/150], Loss: 0.1542, Time: 0.20s\n",
            "Epoch [47/150], Loss: 0.1498, Time: 0.19s\n",
            "Epoch [48/150], Loss: 0.1584, Time: 0.20s\n",
            "Epoch [49/150], Loss: 0.1480, Time: 0.20s\n",
            "Epoch [50/150], Loss: 0.1417, Time: 0.20s\n",
            "Epoch [51/150], Loss: 0.1602, Time: 0.20s\n",
            "Epoch [52/150], Loss: 0.1338, Time: 0.20s\n",
            "Epoch [53/150], Loss: 0.1168, Time: 0.20s\n",
            "Epoch [54/150], Loss: 0.1271, Time: 0.20s\n",
            "Epoch [55/150], Loss: 0.1032, Time: 0.20s\n",
            "Epoch [56/150], Loss: 0.1316, Time: 0.20s\n",
            "Epoch [57/150], Loss: 0.1305, Time: 0.20s\n",
            "Epoch [58/150], Loss: 0.1368, Time: 0.20s\n",
            "Epoch [59/150], Loss: 0.1422, Time: 0.20s\n",
            "Epoch [60/150], Loss: 0.1259, Time: 0.20s\n",
            "Epoch [61/150], Loss: 0.1245, Time: 0.20s\n",
            "Epoch [62/150], Loss: 0.1227, Time: 0.20s\n",
            "Epoch [63/150], Loss: 0.1426, Time: 0.20s\n",
            "Epoch [64/150], Loss: 0.1247, Time: 0.20s\n",
            "Epoch [65/150], Loss: 0.1266, Time: 0.21s\n",
            "Epoch [66/150], Loss: 0.1108, Time: 0.20s\n",
            "Epoch [67/150], Loss: 0.1219, Time: 0.20s\n",
            "Epoch [68/150], Loss: 0.1332, Time: 0.20s\n",
            "Epoch [69/150], Loss: 0.1437, Time: 0.19s\n",
            "Epoch [70/150], Loss: 0.1300, Time: 0.21s\n",
            "Epoch [71/150], Loss: 0.1201, Time: 0.21s\n",
            "Epoch [72/150], Loss: 0.1140, Time: 0.20s\n",
            "Epoch [73/150], Loss: 0.1084, Time: 0.19s\n",
            "Epoch [74/150], Loss: 0.1129, Time: 0.20s\n",
            "Epoch [75/150], Loss: 0.1344, Time: 0.20s\n",
            "Epoch [76/150], Loss: 0.1227, Time: 0.20s\n",
            "Epoch [77/150], Loss: 0.1189, Time: 0.20s\n",
            "Epoch [78/150], Loss: 0.1304, Time: 0.20s\n",
            "Epoch [79/150], Loss: 0.1355, Time: 0.20s\n",
            "Epoch [80/150], Loss: 0.1028, Time: 0.20s\n",
            "Epoch [81/150], Loss: 0.1048, Time: 0.20s\n",
            "Epoch [82/150], Loss: 0.1155, Time: 0.20s\n",
            "Epoch [83/150], Loss: 0.1050, Time: 0.20s\n",
            "Epoch [84/150], Loss: 0.1431, Time: 0.20s\n",
            "Epoch [85/150], Loss: 0.1483, Time: 0.22s\n",
            "Epoch [86/150], Loss: 0.0912, Time: 0.21s\n",
            "Epoch [87/150], Loss: 0.1113, Time: 0.20s\n",
            "Epoch [88/150], Loss: 0.1006, Time: 0.20s\n",
            "Epoch [89/150], Loss: 0.0997, Time: 0.20s\n",
            "Epoch [90/150], Loss: 0.1235, Time: 0.21s\n",
            "Epoch [91/150], Loss: 0.1052, Time: 0.21s\n",
            "Epoch [92/150], Loss: 0.1735, Time: 0.21s\n",
            "Epoch [93/150], Loss: 0.1007, Time: 0.21s\n",
            "Epoch [94/150], Loss: 0.1401, Time: 0.21s\n",
            "Epoch [95/150], Loss: 0.0923, Time: 0.21s\n",
            "Epoch [96/150], Loss: 0.1390, Time: 0.21s\n",
            "Epoch [97/150], Loss: 0.1251, Time: 0.20s\n",
            "Epoch [98/150], Loss: 0.1212, Time: 0.20s\n",
            "Epoch [99/150], Loss: 0.0979, Time: 0.19s\n",
            "Epoch [100/150], Loss: 0.0992, Time: 0.21s\n",
            "Epoch [101/150], Loss: 0.0872, Time: 0.20s\n",
            "Epoch [102/150], Loss: 0.1054, Time: 0.20s\n",
            "Epoch [103/150], Loss: 0.1047, Time: 0.20s\n",
            "Epoch [104/150], Loss: 0.1023, Time: 0.21s\n",
            "Epoch [105/150], Loss: 0.1087, Time: 0.21s\n",
            "Epoch [106/150], Loss: 0.1072, Time: 0.20s\n",
            "Epoch [107/150], Loss: 0.1072, Time: 0.21s\n",
            "Epoch [108/150], Loss: 0.0957, Time: 0.20s\n",
            "Epoch [109/150], Loss: 0.1074, Time: 0.21s\n",
            "Epoch [110/150], Loss: 0.1566, Time: 0.21s\n",
            "Epoch [111/150], Loss: 0.1012, Time: 0.20s\n",
            "Epoch [112/150], Loss: 0.1003, Time: 0.20s\n",
            "Epoch [113/150], Loss: 0.1258, Time: 0.21s\n",
            "Epoch [114/150], Loss: 0.1036, Time: 0.20s\n",
            "Epoch [115/150], Loss: 0.1084, Time: 0.20s\n",
            "Epoch [116/150], Loss: 0.0808, Time: 0.20s\n",
            "Epoch [117/150], Loss: 0.1061, Time: 0.21s\n",
            "Epoch [118/150], Loss: 0.1474, Time: 0.20s\n",
            "Epoch [119/150], Loss: 0.1087, Time: 0.20s\n",
            "Epoch [120/150], Loss: 0.1144, Time: 0.20s\n",
            "Epoch [121/150], Loss: 0.1480, Time: 0.20s\n",
            "Epoch [122/150], Loss: 0.1111, Time: 0.20s\n",
            "Epoch [123/150], Loss: 0.1231, Time: 0.20s\n",
            "Epoch [124/150], Loss: 0.1058, Time: 0.20s\n",
            "Epoch [125/150], Loss: 0.1162, Time: 0.20s\n",
            "Epoch [126/150], Loss: 0.1029, Time: 0.19s\n",
            "Epoch [127/150], Loss: 0.1009, Time: 0.21s\n",
            "Epoch [128/150], Loss: 0.1034, Time: 0.21s\n",
            "Epoch [129/150], Loss: 0.1102, Time: 0.20s\n",
            "Epoch [130/150], Loss: 0.1195, Time: 0.21s\n",
            "Epoch [131/150], Loss: 0.1294, Time: 0.20s\n",
            "Epoch [132/150], Loss: 0.1141, Time: 0.20s\n",
            "Epoch [133/150], Loss: 0.1315, Time: 0.21s\n",
            "Epoch [134/150], Loss: 0.1204, Time: 0.20s\n",
            "Epoch [135/150], Loss: 0.1133, Time: 0.20s\n",
            "Epoch [136/150], Loss: 0.0899, Time: 0.21s\n",
            "Epoch [137/150], Loss: 0.0742, Time: 0.21s\n",
            "Epoch [138/150], Loss: 0.1058, Time: 0.20s\n",
            "Epoch [139/150], Loss: 0.1275, Time: 0.21s\n",
            "Epoch [140/150], Loss: 0.1115, Time: 0.20s\n",
            "Epoch [141/150], Loss: 0.0843, Time: 0.20s\n",
            "Epoch [142/150], Loss: 0.0947, Time: 0.20s\n",
            "Epoch [143/150], Loss: 0.1092, Time: 0.20s\n",
            "Epoch [144/150], Loss: 0.1207, Time: 0.21s\n",
            "Epoch [145/150], Loss: 0.1227, Time: 0.22s\n",
            "Epoch [146/150], Loss: 0.1189, Time: 0.21s\n",
            "Epoch [147/150], Loss: 0.0990, Time: 0.21s\n",
            "Epoch [148/150], Loss: 0.0949, Time: 0.22s\n",
            "Epoch [149/150], Loss: 0.0988, Time: 0.21s\n",
            "Epoch [150/150], Loss: 0.0924, Time: 0.21s\n",
            "\n",
            "Final Model Accuracy with Optimal Hyperparameters: 98.54%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}